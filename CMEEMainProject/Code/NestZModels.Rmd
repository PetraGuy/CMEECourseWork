---
title: "NestZModels"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
rm(list = ls())
cat("\014")
library(dplyr)
library(ggplot2)
library(visreg)
library(car) #for vif
library(GGally) # for ggpairs
library(gridExtra)
library(MuMIn)
library(reshape)
library(energy)#dcor
library(corrplot)

library(corrr)

```

```{r, echo=FALSE}
#Get site vars and nest slopes

AllSiteVars = read.csv("../Data/CompleteSiteLevelVars.csv")
nestdata = readRDS("nest_mixed_model_fits.RDS")
AllPlotVars= read.csv("../Data/AllPlotsVarsRichness.csv")

#All site vars has some cols we know are not useful, delete these now

cols = colnames(AllSiteVars)
```

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
todelete = c(1,3,4,5,6,7,8,9,11,12,14,18,21, 22,23,24,25,26,27,28,29,30,35)
Sitevars = AllSiteVars[-todelete]
colnames(Sitevars) = c("Site","PHI","Buffer","Num_NVC","sd_pH", "sd_SOM" ,"sd_LBA",
                        "sd_meanDBH","meanDBH" , "meanph" , "meanSOM" , "meanLBA" ,
                        "area_ratio" )
# ps I have removed no trees after analysis, not shown. If I include all the analysis it makes the discussion to convoluted
# in retrospect no trees is not required, obvs realted to mean dbh and sd meand dbh, and since I created it,
#it wasnt a collected variable, I think its logical to drop it - it was a onbvuscating, unnecessary addition
# same fo rnumber major soil groups.
```


```{r message=FALSE, warning=FALSE, paged.print=FALSE}
#take site and slope from nestdata
NestSlope = nestdata[-c(2,4,5)]
#join to SiteData
SitedataZ = inner_join(Sitevars,NestSlope)
SitedataZ[is.na(SitedataZ)] = 0

```
 
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
# first look for response of z to the variables

melted = melt(SitedataZ[-1], id.vars = "slope")


ggplot(melted, aes(x = value, y = slope))+
  geom_point()+
  geom_smooth(method = loess)+
  facet_wrap(~variable, scales = "free")

```

```{r echo=FALSE}
corrs = sort(round(apply(SitedataZ[-c(1,14)],2, function(x) dcor(x,SitedataZ$slope)), digits = 2), decreasing = TRUE)
corrs = as.data.frame(corrs)
corrs
```
The two variables with the lowest correlation coefficients (dcor distance correlation) to slope are meanLBA and sd pH,(Corr = 0.14,0.12)

The outliers in PHI, area_ratio and sd_SOM make it had to see the reponse of slope to these variable. Initially I removed some outliers, but the distribution of some variables, eg sd_SOM was very right skew, therefore decided to look at log fit instead.

```{r message=FALSE, warning=FALSE, paged.print=FALSE}


# outliers = c(23,53,74,76)# found by Sitevars%>%filter(area_ratio==max(area_ratio))..etc
# SitedataZ = SitedataZ%>%filter(Site!=23)
# SitedataZ = SitedataZ%>%filter(Site!=53)
# SitedataZ = SitedataZ%>%filter(Site!=74)
# SitedataZ = SitedataZ%>%filter(Site!=76)
# SitedataZ = SitedataZ%>%filter(Site!=8)


#PS - these four lines because  the usua code of Site!=outliers stopped running.

melted = melt(SitedataZ[-1], id.vars = "slope")
ggplot(melted, aes(x = log(value), y = slope))+
  geom_point()+
  geom_smooth(method = loess)+
  facet_wrap(~variable, scales = "free")



```

```{r}
tmp = SitedataZ%>%filter(Site != 25)
slopecor =sort(round(apply(tmp[-c(1,14)],2, function(x) dcor(log(x),tmp$slope)),  2), decreasing = TRUE)
slopecor = as.data.frame(slopecor)
slopecor

```


```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
vars = SitedataZ[-c(1,16)]
mcor = round(cor(vars, method = "pearson"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
         method = "circle", tl.cex = 0.5, tl.col = 'black',tl.srt=45,
         order = "hclust", diag = FALSE,
         title = "pearson",
         mar=c(0,0,1,0))
```

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
vars = SitedataZ[-c(1,16)]
mcor = round(cor(vars, method = "kendall"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
         method = "circle", tl.cex = 0.5, tl.col = 'black',tl.srt=45,
         order = "hclust", diag = FALSE, title = "kendal", mar=c(0,0,1,0))
```

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
network_plot(correlate(vars, method = "pearson"), min_cor=0.4)

```
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
network_plot(correlate(vars, method = "kendall"), min_cor=0.4)

```

Using either pearson or kendal correlations (even having removed outliers which migh influence the pearson correlation) there are correlations above 0.4 between the means and sd. Splitting the data into two groups to separate these variables might give a less correlated set of variables.
I cant think why these correlations are so strong?? But you can see them (sort of) in this plot of SOM in each site

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}

ggplot(AllPlotVars, aes(x = reorder(as.factor(Site), SOMYr2, median), y = SOMYr2))+
  geom_boxplot()+
  xlab("Site")+
  theme(axis.text.x = element_text(angle=90, hjust=1))
```


#Splitting the data into sd and means

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
# taking all remaing vars and either means or sd
Set_sd = SitedataZ[c(1,2,3,4,5,6,7,8,13,14)] #11 inc Site, slope
Set_mean = SitedataZ[c(1,2,3,4,9,10,11,12,13,14)]#11, inc Site, slope
# look at correlations now
```


```{r echo=FALSE, message=FALSE, warning=FALSE}

mcor = round(cor(Set_sd[-c(1,10)], method = "pearson"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
         method = "number", tl.cex = 0.5, tl.col = 'black',tl.srt=45,
         order = "hclust", diag = FALSE, title = "pearson",mar=c(0,0,1,0) )
```
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
mcor = round(cor(Set_sd[-c(1,10)], method = "kendall"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
         method = "number", tl.cex = 0.5, tl.col = 'black',tl.srt=45,
         order = "hclust", diag = FALSE,title = "kendall", mar=c(0,0,1,0))
```

The Pearson method shows correlation between buffer, and sd of SOM and meandbh. The Kendall does not show any correlations above 0.25. This may be due to the outliers in SOM and mean DBH which are influencing the Pearson calculation.

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
tmp = Set_sd%>%filter(Site != 25)
slopecor =sort(round(apply(tmp[-c(1,10)],2, function(x) dcor(log(x),tmp$slope)),  2), decreasing = TRUE)
slopecor = as.data.frame(slopecor)
slopecor

```

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
 tmp = Set_mean%>%filter(Site != 25)
slopecor =sort(round(apply(tmp[-c(1,10)],2, function(x) dcor(log(x),tmp$slope)),  2), decreasing = TRUE)
slopecor = as.data.frame(slopecor)
slopecor

```

Both sets show a correlation (distance using dcor) of 0.42 with PHI with the remaining correlations  being very similar. The selection of variables could all potentially have an effect on richness - which in turn must affect slope.  This model analysis is looking at the slope of the SAC from the ln/ln lme model. This model can be thought of as an "averaging" effect of the alpha diversity of each plot in the site. The effect of any environmental variables on the slope at this scale should therefore be small compared to the effect of the increasing area.

#Models
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
data = Set_mean[-1]
mod_mean = lm(slope~., data=data, na.action = "na.fail")
#have a look at the linear model
par(mfrow =c(2,2))
plot(mod_mean)
```

The plots are for additve linear model to the mean set of variables. There is slight lack of linearity in the residuals plot due to one outlier. The residuals do not appear to deviate substantially from normality. Site 23 (point 78) appears to be influential - this is the outlier in PHI 

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
models = dredge(mod_mean)
get.models(models, subset = delta<1)


```

```{r}
head(models)
```

The "best" two models use number NVC, meanpH, meanSOM, PHI and either do or do not include area_ratio.
We expect meanSOM to effect pH, and that pH effects richness, with greatest richness occurring around neutral pH - so I am not sure why we would also include meanpH as well as meanSOM.  

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
g1 = ggplot(AllSiteVars, aes(x = meanph, y = meanSOM))+
  geom_point()+
  geom_smooth(method = loess)+
  ggtitle("Site level")


g5 = ggplot(AllPlotVars, aes(x = pHYr2, y = SOMYr2))+
  geom_point()+
  geom_smooth(method = loess)+
  ggtitle("Plot level")



grid.arrange(g1,g5, nrow = 1 )
```

The plots suggest that in these sites meanSOM is not strongly correlated with meanpH at Site level, but at plot level there is a negative correlation below pH5, However,  there is a lot of scatter. 

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
g1 = ggplot(AllPlotVars, aes(x = log(SOMYr2), y = plot_richness), na.rm = TRUE)+
  geom_point()+
  geom_smooth(method = loess)+
  ggtitle("Plot level")

g2 = ggplot(AllPlotVars, aes(x = log(pHYr2), y = plot_richness))+
   geom_point()+
  geom_smooth(method = loess)+
  ggtitle("Plot level")
 
g3 =  ggplot(AllSiteVars, aes(x = meanph, y = Richness))+
   geom_point()+
  geom_smooth(method = loess)+
  ggtitle("Site level")
  
g4 =  ggplot(AllSiteVars, aes(x =meanSOM, y = Richness))+
   geom_point()+
  geom_smooth(method = loess)+
  ggtitle("Site level")


grid.arrange(g1,g2,g4,g3)
```
The richness at site and plot level does not have a strong linear correlation with pH, there is the expected unimodal peak, which is stronger at site level. This would suggest that pH is s strong influencing factor on richness, and thereby z, but its effect is not linear. Therefore the coefficient of the linear term in the model could be expected to be small and less significant than a non-linear term.

The richness as site or plot level does not appear to correlate strongly with SOM, and its effect on the slope would therefore be small

These plots suggest that meanpH would be a better term for predicting richness and therefore slope, but that it should be non-linear.




