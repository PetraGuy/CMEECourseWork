richness = extrap_rich(zetas,order)
richness_max = extrap_rich(zetamax,order)
richnesses[1] = richness_min
richnesses[2] = richness
richnesses[3] = richness_max
extrap_richness[[i]] = richnesses
}
# you still get many w
View(extrap_richness)
View(extrap_richness)
View(extrap_richness)
extrap_richness = list()
for (i in site_list){
#browser()
richnesses = vector()
coef = get_coefs(i)
orders = floor(most_accurate%>%filter(Site == i)%>%select(orders))
order=orders[[1]]
if (order<=50){
order = order
}  else {
order = 50
}
zetamins = get_site_zetas(coef[[1]][[1]],coef[[2]][[1]],coef[[3]][[1]],order)
zetas = get_site_zetas(coef[[1]][[2]],coef[[2]][[2]],coef[[3]][[2]],order)
zetamax = get_site_zetas(coef[[1]][[3]],coef[[2]][[3]],coef[[3]][[3]],order)
richness_min = extrap_rich(zetamins,order)
richness = extrap_rich(zetas,order)
richness_max = extrap_rich(zetamax,order)
richnesses[1] = richness_min
richnesses[2] = richness
richnesses[3] = richness_max
extrap_richness[[i]] = richnesses
}
View(extrap_richness)
View(extrap_richness)
site_list = most_accurate$Site
extrap_richness = list()
for (i in site_list){
#browser()
richnesses = vector()
coef = get_coefs(i)
orders = floor(most_accurate%>%filter(Site == i)%>%select(orders))
order=orders[[1]]
if (order<=50){
order = order
}  else {
order = 50
}
zetamins = get_site_zetas(coef[[1]][[1]],coef[[2]][[1]],coef[[3]][[1]],order)
zetas = get_site_zetas(coef[[1]][[2]],coef[[2]][[2]],coef[[3]][[2]],order)
zetamax = get_site_zetas(coef[[1]][[3]],coef[[2]][[3]],coef[[3]][[3]],order)
richness_min = extrap_rich(zetamins,order)
richness = extrap_rich(zetas,order)
richness_max = extrap_rich(zetamax,order)
richnesses[1] = richness_min
richnesses[2] = richness
richnesses[3] = richness_max
extrap_richness[[i]] = richnesses
}
View(extrap_richness)
View(extrap_richness)
i = 35
richnesses = vector()
coef = get_coefs(i)
orders = floor(most_accurate%>%filter(Site == i)%>%select(orders))
order=orders[[1]]
if (order<=50){
order = order
}  else {
order = 50
}
zetamins = get_site_zetas(coef[[1]][[1]],coef[[2]][[1]],coef[[3]][[1]],order)
zetas = get_site_zetas(coef[[1]][[2]],coef[[2]][[2]],coef[[3]][[2]],order)
zetamax = get_site_zetas(coef[[1]][[3]],coef[[2]][[3]],coef[[3]][[3]],order)
richness_min = extrap_rich(zetamins,order)
richness = extrap_rich(zetas,order)
richness_max = extrap_rich(zetamax,order)
richnesses[1] = richness_min
richnesses[2] = richness
richnesses[3] = richness_max
richnesses
site_list = most_accurate$Site
site_list
extrap_richness = list()
for (i in site_list){
#browser()
richnesses = vector()
coef = get_coefs(i)
orders = floor(most_accurate%>%filter(Site == i)%>%select(orders))
order=orders[[1]]
if (order<=50){
order = order
}  else {
order = 50
}
zetamins = get_site_zetas(coef[[1]][[1]],coef[[2]][[1]],coef[[3]][[1]],order)
zetas = get_site_zetas(coef[[1]][[2]],coef[[2]][[2]],coef[[3]][[2]],order)
zetamax = get_site_zetas(coef[[1]][[3]],coef[[2]][[3]],coef[[3]][[3]],order)
richness_min = extrap_rich(zetamins,order)
richness = extrap_rich(zetas,order)
richness_max = extrap_rich(zetamax,order)
richnesses[1] = richness_min
richnesses[2] = richness
richnesses[3] = richness_max
extrap_richness[[i]] = richnesses
}
extrap_richness[[35]]
View(subset_woods_cut)
View(subset_woods_cut)
knitr::opts_chunk$set(echo = FALSE)
library(dplyr)
library(ggplot2)
rm(list = ls())
cat("\014")
emp_zetas = readRDS("empirical_zetas.RDS")
modelled_coefs = readRDS("zeta_coefficients.RDS")
modelled_zetas = readRDS("modelled_zetas.RDS")
new_mod_zetas = readRDS("new_model_zetas")
ground_flora = read.csv("../../Data/GroundCover.csv")
ground_flora = ground_flora%>%filter(Yr_2 == 2)
veg_codes = read.csv("../../Data/vegetation_codes.csv")
colnames(ground_flora) = c("SITE", "PLOT","NEST","Cover","BRC_number","Year")
colnames(veg_codes) = c("Species", "BRC_number")
flora = ground_flora%>% inner_join(veg_codes)
Richness = read.csv("../../data/SiteRichness.csv")
Richness = Richness[,-1]
CompleteSiteLevelvars = read.csv("../../Data/CompleteSiteLevelVars.csv")
sites = c(1:4,6,7,9:23,25:43,45:61,63,65,66,68:93,95:103)
sites_to_remove = c(5,8,24,44,62,64,67,94)
get_rich_mod = function(data){
#browser()
nCr = vector()
Rich_mod = vector()
for (i in 1:95){
zs = data[,i]
l = length(zs)
z = vector()
sign = vector()
for (j in 1:l){
nCr[j] = choose(l,j)
sign[j] = (-1)^(j+1)
z[j] = zs[j]
}
S = nCr*sign*z
Rich_mod[i] = sum(S)
}
return(Rich_mod)
}
#check:
emp_zetas_subset = emp_zetas[-(sites_to_remove),]
Richness_check = get_rich_mod(emp_zetas_subset)
mod_rich = get_rich_mod(new_mod_zetas)
a = readRDS("a.RDS")
b =  readRDS("b.RDS")
c = readRDS("c.RDS")
new_mod_zetas = readRDS("new_model_zetas")
new_mod_coefs = readRDS("new_mod_coefs")
areas = CompleteSiteLevelvars%>%select(Site,Area_ha,Richness)
rownames(areas) = areas$Site
areas_sorted = areas[order(areas$Site),]
subset_woods = areas_sorted[-(sites_to_remove),]
subset_woods$orders = (subset_woods$Area_ha)*5 # areas in ha, so areax10000/200 = areax5
#first just calc richness to order = 16
#get the databases in the right order
subset_woods$mod_rich = mod_rich
rownames(subset_woods) = c(1:95)
outliers = c(44,55,70,72,90,91)
subset_woods_cut = subset_woods[-(outliers),]
data = as.data.frame(cbind(subset_woods_cut$Richness,subset_woods_cut$mod_rich))
colnames(data) = c("Observed_Richness", "Predicted_Richness")
ggplot(data = data, aes (x = Predicted_Richness, y = Observed_Richness))+
geom_point()+
geom_abline(intercept = 0, slope = 1)+
ylab("Observed Richness")+
xlab("Predicted Richness")+
ggtitle("Observed and Predicted Richness")+
annotate("text", x =35, y = 120, label = "zeta == ce^x^-a*e^-bx", parse=TRUE)
?cor
#lets extrapolate theones that are the most accurate, where most
#subset_woods_cut is reduced set of woods where nls did not converge
#and also where richness wasnt crazy crazy
# find ones that are within 10%
error = (subset_woods_cut$Richness - subset_woods_cut$mod_rich)/subset_woods_cut$Richness
subset_woods_cut$error = error
most_accurate = subset_woods_cut%>%filter(between(error, -0.1, 0.1))
#now extrapolate richness of those to the required number of orders
get_a_zeta = function(i,a,b,c){
zeta = c*exp(i^a)*exp(i*b)
return(zeta)
}
get_site_zetas = function(a,b,c,order){
zetas = vector()
for (j in 1:order){
zetas[j] = get_a_zeta(j,a,b,c)
}
return(zetas)
}
extrap_rich = function(zetas,orders){
z=vector()
nCr = vector()
Rich_mod = vector()
sign = vector()
for (j in 1:orders){
nCr[j] = choose(orders,j)
sign[j] = (-1)^(j+1)
z[j] = zetas[j]
}
S = nCr*sign*z
Rich_mod = sum(S)
return(Rich_mod)
}
get_coefs = function(i){
coefficients = vector()
coeffs = list()
coefficients[1] = new_mod_coefs[[i]][[1]] #a
coefficients[2] = new_mod_coefs[[i]][[4]] #se a
coefficients[3] = new_mod_coefs[[i]][[2]] #b
coefficients[4] = new_mod_coefs[[i]][[5]] #se b
coefficients[5] = new_mod_coefs[[i]][[3]] #c
coefficients[6] = new_mod_coefs[[i]][[6]] #se c
amin = coefficients[1]+coefficients[2]
a = coefficients[1]
amax = coefficients[1]-coefficients[2]
bmin = coefficients[3]+coefficients[4]
b = coefficients[3]
bmax = coefficients[3]-coefficients[4]
cmin = coefficients[5]-coefficients[6]
c = coefficients[5]
cmax = coefficients[5]+coefficients[6]
as = c(amin,a,amax)
bs = c(bmin,b,bmax)
cs = c(cmin,c,cmax)
coeffs[[1]] = as
coeffs[[2]] = bs
coeffs[[3]] = cs
return(coeffs) #coeffs[[1]] is amin,a and amax for site 1
}
site_list = most_accurate$Site
extrap_richness = list()
for (i in site_list){
#browser()
richnesses = vector()
coef = get_coefs(i)
orders = floor(most_accurate%>%filter(Site == i)%>%select(orders))
order=orders[[1]]
if (order<=50){
order = order
}  else {
order = 50
}
zetamins = get_site_zetas(coef[[1]][[1]],coef[[2]][[1]],coef[[3]][[1]],order)
zetas = get_site_zetas(coef[[1]][[2]],coef[[2]][[2]],coef[[3]][[2]],order)
zetamax = get_site_zetas(coef[[1]][[3]],coef[[2]][[3]],coef[[3]][[3]],order)
richness_min = extrap_rich(zetamins,order)
richness = extrap_rich(zetas,order)
richness_max = extrap_rich(zetamax,order)
richnesses[1] = richness_min
richnesses[2] = richness
richnesses[3] = richness_max
extrap_richness[[i]] = richnesses
}
# you still get many weird values - I guess because either nCr is so huge, even a tiny zeta becomes an issue.
#try a subset of sites with orders <=50
site_list = c(68,28,63,103,83,25,33,65,95)
#if you limit the number of orders to 50 you can extrapolate all the "most accurate" sites
#lets extrapolate theones that are the most accurate, where most
#subset_woods_cut is reduced set of woods where nls did not converge
#and also where richness wasnt crazy crazy
# find ones that are within 10%
error = (subset_woods_cut$Richness - subset_woods_cut$mod_rich)/subset_woods_cut$Richness
subset_woods_cut$error = error
most_accurate = subset_woods_cut%>%filter(between(error, -0.1, 0.1))
#now extrapolate richness of those to the required number of orders
get_a_zeta = function(i,a,b,c){
zeta = c*exp(i^a)*exp(i*b)
return(zeta)
}
get_site_zetas = function(a,b,c,order){
zetas = vector()
for (j in 1:order){
zetas[j] = get_a_zeta(j,a,b,c)
}
return(zetas)
}
extrap_rich = function(zetas,orders){
z=vector()
nCr = vector()
Rich_mod = vector()
sign = vector()
for (j in 1:orders){
nCr[j] = choose(orders,j)
sign[j] = (-1)^(j+1)
z[j] = zetas[j]
}
S = nCr*sign*z
Rich_mod = sum(S)
return(Rich_mod)
}
get_coefs = function(i){
coefficients = vector()
coeffs = list()
coefficients[1] = new_mod_coefs[[i]][[1]] #a
coefficients[2] = new_mod_coefs[[i]][[4]] #se a
coefficients[3] = new_mod_coefs[[i]][[2]] #b
coefficients[4] = new_mod_coefs[[i]][[5]] #se b
coefficients[5] = new_mod_coefs[[i]][[3]] #c
coefficients[6] = new_mod_coefs[[i]][[6]] #se c
amin = coefficients[1]+coefficients[2]
a = coefficients[1]
amax = coefficients[1]-coefficients[2]
bmin = coefficients[3]+coefficients[4]
b = coefficients[3]
bmax = coefficients[3]-coefficients[4]
cmin = coefficients[5]-coefficients[6]
c = coefficients[5]
cmax = coefficients[5]+coefficients[6]
as = c(amin,a,amax)
bs = c(bmin,b,bmax)
cs = c(cmin,c,cmax)
coeffs[[1]] = as
coeffs[[2]] = bs
coeffs[[3]] = cs
return(coeffs) #coeffs[[1]] is amin,a and amax for site 1
}
site_list = most_accurate$Site
extrap_richness = list()
for (i in site_list){
#browser()
richnesses = vector()
coef = get_coefs(i)
orders = floor(most_accurate%>%filter(Site == i)%>%select(orders))
order=orders[[1]]
if (order<=50){
order = order
}  else {
order = 50
}
zetamins = get_site_zetas(coef[[1]][[1]],coef[[2]][[1]],coef[[3]][[1]],order)
zetas = get_site_zetas(coef[[1]][[2]],coef[[2]][[2]],coef[[3]][[2]],order)
zetamax = get_site_zetas(coef[[1]][[3]],coef[[2]][[3]],coef[[3]][[3]],order)
richness_min = extrap_rich(zetamins,order)
richness = extrap_rich(zetas,order)
richness_max = extrap_rich(zetamax,order)
richnesses[1] = richness_min
richnesses[2] = richness
richnesses[3] = richness_max
extrap_richness[[i]] = richnesses
}
# you still get many weird values - I guess because either nCr is so huge, even a tiny zeta becomes an issue.
#try a subset of sites with orders <=50
site_list = c(68,28,63,103,83,25,33,65,95)
#if you limit the number of orders to 50 you can extrapolate all the "most accurate" sites
View(most_accurate)
View(emp_zetas)
View(extrap_richness)
View(new_mod_zetas)
View(new_mod_zetas)
new_mod_coefs[[44]]
knitr::opts_chunk$set(echo = FALSE)
library(dplyr)
library(ggplot2)
rm(list = ls())
cat("\014")
emp_zetas = readRDS("empirical_zetas.RDS")
modelled_coefs = readRDS("zeta_coefficients.RDS")
modelled_zetas = readRDS("modelled_zetas.RDS")
new_mod_zetas = readRDS("new_model_zetas")
ground_flora = read.csv("../../Data/GroundCover.csv")
ground_flora = ground_flora%>%filter(Yr_2 == 2)
veg_codes = read.csv("../../Data/vegetation_codes.csv")
colnames(ground_flora) = c("SITE", "PLOT","NEST","Cover","BRC_number","Year")
colnames(veg_codes) = c("Species", "BRC_number")
flora = ground_flora%>% inner_join(veg_codes)
Richness = read.csv("../../data/SiteRichness.csv")
Richness = Richness[,-1]
CompleteSiteLevelvars = read.csv("../../Data/CompleteSiteLevelVars.csv")
sites = c(1:4,6,7,9:23,25:43,45:61,63,65,66,68:93,95:103)
sites_to_remove = c(5,8,24,44,62,64,67,94)
modelled_coefs[[44]]
modelled_coefs[[44]]
View(modelled_coefs)
modelled_coefs[[1]]
View(new_mod_zetas)
View(new_mod_zetas)
a = readRDS("a.RDS")
b =  readRDS("b.RDS")
c = readRDS("c.RDS")
new_mod_zetas = readRDS("new_model_zetas")
new_mod_coefs = readRDS("new_mod_coefs")
areas = CompleteSiteLevelvars%>%select(Site,Area_ha,Richness)
rownames(areas) = areas$Site
areas_sorted = areas[order(areas$Site),]
subset_woods = areas_sorted[-(sites_to_remove),]
subset_woods$orders = (subset_woods$Area_ha)*5 # areas in ha, so areax10000/200 = areax5
#first just calc richness to order = 16
#get the databases in the right order
subset_woods$mod_rich = mod_rich
new_mod_zetas = readRDS("new_model_zetas")
new_mod_coefs = readRDS("new_mod_coefs")
new_mod_coefs[[44]]
new_mod_coefs = readRDS("new_mod_coefs")
View(new_mod_coefs)
new_mod_coefs[[40]]
View(emp_zetas)
zetas = na.omit(emp_zetas[,15])
zetas
setwd("C:/dev/code/CMEECourseWork/CMEEMainProject/Code/Zeta")
Richness = read.csv("../../data/SiteRichness.csv")
View(Richness)
colnames(Richness) = c("Site","Richness")
new_mod_coefs = readRDS("new_mod_coefs")
View(emp_zetas)
get_emp_zetas = function(i){
zetas = na.omit(emp_zetas[,i])
end_richness = Richness[i]
}
new_mod_coefs[[1]]
library(ggplot2)
library(dplyr)
library(zetadiv)
rm(list = ls())
cat("\014")
ground_flora = read.csv("../../Data/GroundCover.csv")
ground_flora = ground_flora%>%filter(Yr_2 == 2)
veg_codes = read.csv("../../Data/vegetation_codes.csv")
colnames(ground_flora) = c("SITE", "PLOT","NEST","Cover","BRC_number","Year")
colnames(veg_codes) = c("Species", "BRC_number")
flora = ground_flora%>% inner_join(veg_codes)
Richness = read.csv("../../Data/SiteRichness.csv")
CompleteSiteLevelvars = read.csv("../../Data/CompleteSiteLevelVars.csv")
library(ggplot2)
library(dplyr)
library(zetadiv)
rm(list = ls())
cat("\014")
ground_flora = read.csv("../../Data/GroundCover.csv")
ground_flora = ground_flora%>%filter(Yr_2 == 2)
veg_codes = read.csv("../../Data/vegetation_codes.csv")
colnames(ground_flora) = c("SITE", "PLOT","NEST","Cover","BRC_number","Year")
colnames(veg_codes) = c("Species", "BRC_number")
flora = ground_flora%>% inner_join(veg_codes)
Richness = read.csv("../../Data/SiteRichness.csv")
CompleteSiteLevelvars = read.csv("../../Data/CompleteSiteLevelVars.csv")
View(flora)
View(ground_flora)
?match
sitenum = 1
Site = flora%>%filter(SITE==sitenum)     # extract my site according to sitenum
BRC = unique(Site$BRC_number)            # make sure there are no duplicates
BRC = as.character(BRC)
columns = length(unique(Site$BRC_number))# need to know how many species there are
rows = length(unique(Site$PLOT))         # need to know how many plots there are
Sitedf = data.frame(matrix(ncol = columns, nrow = rows)) # make a matrix of dims plots x species
colnames(Sitedf) = BRC                  # the columns are the species
plots = unique(Site$PLOT)
Sitedf$plotnumber = plots
View(Sitedf)
View(Site)
View(Richness)
i = 1
plot_num = plots[i]
plots
plot-num
plot_num
plot = Site%>%filter(PLOT==plot_num)
plot
matches
matches = match(plot$BRC_number,BRC) #see how many BRC matches there are in BRC col
matches
for (j in 1:length(matches)){
col = matches[j]
Sitedf[i,col] = 1
}
View(Sitedf)
#the data I have is in the form of a long data frame with columns for site, plot, nest and BRC code.
#so you probably aren't interested in the first bit of this code - I'm just getting
#taking out each individual site
create_presence_absence = function(sitenum){
Site = flora%>%filter(SITE==sitenum)     # extract my site from my flora df according to sitenum
BRC = unique(Site$BRC_number)            # make sure there are no duplicates
BRC = as.character(BRC)
columns = length(unique(Site$BRC_number))# need to know how many species there are
rows = length(unique(Site$PLOT))         # need to know how many plots there are
Sitedf = data.frame(matrix(ncol = columns, nrow = rows)) # make a matrix of dims plots x species
colnames(Sitedf) = BRC                  # the columns are the species
plots = unique(Site$PLOT)
Sitedf$plotnumber = plots             # now you have a df with colnames for each BRC code
# that occur in a site and a row for each plot
# these are the bits that make the presence absence df
# first find matches to a BRC
for (i in seq_along(plots)){
plot_num = plots[i]    #for each plot in a site
plot = Site%>%filter(PLOT==plot_num) # get the species list for that plot
matches = match(plot$BRC_number,BRC) #see how many BRC matches there are in BRC col
#thien turn the matches into 1's
for (j in 1:length(matches)){
col = matches[j]
Sitedf[i,col] = 1
}
}
Sitedf[is.na(Sitedf)]=0
return(Sitedf)
}
pres_abs_dfs = list()
for (i in 1:103){
pres_abs_dfs[[i]] = create_presence_absence(i)
}
library(zetadiv)
df =  pres_abs_df # take your presence absence data frame
library(zetadiv)
df =  pres_abs_df # take your presence absence data frame
