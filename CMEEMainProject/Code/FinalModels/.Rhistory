geom_point()+
geom_abline(intercept = 0, slope = 1)+
labs(title = "Observed versus predicted data, mean dataset",
subtitle = subtitle)
summary(fit)
#extract model averaged parameter estimates
predicted_Z = predict(sd_avg_models, full = TRUE)
empirical_Z =  site_data_outlier3$nestZ
fit = lm(empirical_Z ~ predicted_Z)
R2 = round(summary(fit)$r.squared,2)
f = summary(fit)$fstatistic
p = round(pf(f[1],f[2],f[3], lower.tail = F),4)
subtitle = paste("R2 = ",R2, "p = ",p)
data = as.data.frame(cbind(predicted_Z, empirical_Z))
ggplot(data, aes(x = predicted_Z, y = empirical_Z))+
geom_point()+
geom_abline(intercept = 0, slope = 1)+
labs(title = "Observed versus predicted data, sd dataset",
subtitle = subtitle)
summary(fit)
## NB - several libraries mask each other here - arm masks dplyr and corrplot, therefore open libraries #as required.
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
# Richness modelling
rm(list = ls())
cat("\014")
library(dplyr) # everything
library(ggplot2)
library(car) # for vif
library(reshape) # melt
# get the data
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
PlotZdata = read.csv("../../Data/z_ave_fits.csv")
Zs = PlotZdata%>%select(Site, slope)
zeta_r = readRDS("../Zeta/zeta_r")
Site = c(1:103)
zeta_r = as.data.frame(cbind(Site,zeta_r))
site_data = inner_join(site_data,zeta_r)
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
site_data_zs = inner_join(site_data,Zs)
#add in the new random path z's AND expectation method Zs
rand_zs = read.csv("../../Data/rand_zs.csv")
colnames(rand_zs) = c("Site","zr")
exp_zs = read.csv("../../Data/zexp.csv")
colnames(exp_zs) = c("Site","expz")
site_data_zs_zr=inner_join(site_data_zs,rand_zs)
site_data_allzs = inner_join(site_data_zs_zr,exp_zs)
# slect only required variables
#change to either slope or zr or zexp if you want minmax , 1000 random paths or expectation
subset_all = site_data_allzs%>%select("Site","expz","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity","zeta_r")
colnames(subset_all) = c("Site","z","Area",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD","zeta_r")
#remove the wood with the largest area
largest_area = as.numeric(subset_all%>%filter(Area == max(Area))%>%select(Site))
site_data_outlier1 = subset_all%>%filter(Site!=largest_area)
site_data_outlier1 = site_data_outlier1[,-3] # remove area column now
#remove the outlier in PHI
largest_PHI = as.numeric(subset_all%>%filter(PHI == max(PHI))%>%select(Site))
site_data_outlier2 = site_data_outlier1%>%filter(Site!=largest_PHI)
largest_PHI = as.numeric(site_data_outlier2%>%filter(PHI == max(PHI))%>%select(Site))
site_data_outlier3 = site_data_outlier2%>%filter(Site!=largest_PHI)
subset_sd = site_data_outlier3%>%select("Site","z",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio","zeta_r")
subset_mean = site_data_outlier3%>%select("Site","z",
"Northing", "PHI",  "meandbh",
"meanph", "Buffer", "meanSOM","meanLBA",
"meanTD","area_ratio", "no_NVC",
"no_MSG","zeta_r")
# we know richness vs ph usually unimodal around .5, therefore fit to meanpH^2
data = subset_mean[,-1]
z = subset_mean[,2]
data$meanph = (data$meanph)^2
#rescale the data
library(arm) #for standarize
rescaled_mean_data = apply(data[,-1],2, rescale)
rescaled_mean_data = as.data.frame(cbind(z, rescaled_mean_data))
#create the model
mod_mean = lm(z~., data=rescaled_mean_data, na.action = "na.fail")
# we know richness vs ph usually unimodal around .5, therefore fit to meanpH^2
data = subset_sd[,-1]
z = subset_mean[,2]
#rescale the data
library(arm) #for standarize
rescaled_sd_data = apply(data[,-1],2, rescale)
rescaled_sd_data = as.data.frame(cbind(z, rescaled_sd_data))
#create the model
mod_sd = lm(z~., data=rescaled_sd_data, na.action = "na.fail")
summary(mod_mean)
summary(mod_sd)
library(MuMIn) #dredge and avg
#get top models
models = dredge(mod_mean)
model_set = get.models(models, subset = delta<1.5)
#do model averaging, subset means zero method
mean_avg_models = model.avg(model_set, subset)
#select output data
summary = summary(mean_avg_models)
coefs =  mean_avg_models$coefficients
importance =  c(NA,(as.vector(mean_avg_models$importance)))
coef_matrix = summary$coefmat.full
coefs = coef_matrix[,1]
adj_se = coef_matrix[,3]
CI_lower =  coefs - 1.96*adj_se
CI_upper = coefs + 1.96*adj_se
output = round(as.data.frame(cbind(coefs,adj_se, CI_lower, CI_upper, importance)),2)
# make plot of the variables and CI
n = nrow(output)
data = output[c(2:n),]
data = data[,c(1,3,4)]
data = t(data)
data = as.data.frame(data)
melted = melt(data)
fun_mean <- function(x){
data = data.frame(y=mean(x),label=mean(x,na.rm=T))
data = round(data,2)
return(data)}
#(aes_string(x = 'variable', y='value', na.rm = TRUE)
melted$variable = as.factor(melted$variable)# ps, wont plot as separate plots if x continous
ggplot(melted,aes_string(x = 'variable', y ='value' ) )+
geom_boxplot(na.rm = TRUE, width = 0)+
stat_summary(fun.y = mean, geom="point",colour="darkred", size=3) +
stat_summary(fun.data = fun_mean, geom="text", vjust=-0.7)+
stat_summary(geom = "text", label = output$importance[-1],fun.y = max, hjust = 1, colour = "red")+
geom_abline(intercept = 0, slope = 0)+
labs(y = "Effect size and 95%CI",x = "effect")+
labs(title = "Model averaged results for delta <1.5, Plot Zs, Mean dataset",
subtitle = "numbers in red are variable importance")
library(MuMIn) #dredge and avg
#get top models
models = dredge(mod_sd)
model_set = get.models(models, subset = delta<1.5)
#do model averaging, subset means zero method
sd_avg_models = model.avg(model_set, subset)
#select output data
summary = summary(sd_avg_models)
coefs =  sd_avg_models$coefficients
importance =  c(NA,(as.vector(sd_avg_models$importance)))
coef_matrix = summary$coefmat.full
coefs = coef_matrix[,1]
adj_se = coef_matrix[,3]
CI_lower =  coefs - 1.96*adj_se
CI_upper = coefs + 1.96*adj_se
output = round(as.data.frame(cbind(coefs,adj_se, CI_lower, CI_upper, importance)),2)
# make plot of the variables and CI
n = nrow(output)
data = output[c(2:n),]
data = data[,c(1,3,4)]
data = t(data)
data = as.data.frame(data)
melted = melt(data)
fun_mean <- function(x){
data = data.frame(y=mean(x),label=mean(x,na.rm=T))
data = round(data,2)
return(data)}
#(aes_string(x = 'variable', y='value', na.rm = TRUE)
melted$variable = as.factor(melted$variable)# ps, wont plot as separate plots if x continous
ggplot(melted,aes_string(x = 'variable', y ='value' ) )+
geom_boxplot(na.rm = TRUE, width = 0)+
stat_summary(fun.y = mean, geom="point",colour="darkred", size=3) +
stat_summary(fun.data = fun_mean, geom="text", vjust=-0.7)+
stat_summary(geom = "text", label = output$importance[-1],fun.y = max, hjust = 1, colour = "red")+
geom_abline(intercept = 0, slope = 0)+
labs(y = "Effect size and 95%CI",x = "effect")+
labs(title = "Model averaged results for delta <1.5, Plot Zs, SD dataset",
subtitle = "numbers in red are variable importance")
#extract model averaged parameter estimates
predicted_Z = predict(mean_avg_models, full = TRUE)
empirical_Z =  site_data_outlier3$z
fit = lm(empirical_Z ~ predicted_Z)
R2 = round(summary(fit)$r.squared,2)
subtitle = paste("R2 = ",R2)
data = as.data.frame(cbind(predicted_Z, empirical_Z))
ggplot(data, aes(x = predicted_Z, y = empirical_Z))+
geom_point()+
geom_abline(intercept = 0, slope = 1)+
labs(title = "Observed versus predicted data, mean dataset",
subtitle = subtitle)
summary(fit)
#extract model averaged parameter estimates
predicted_Z = predict(sd_avg_models, full = TRUE)
empirical_Z =  site_data_outlier3$z
fit = lm(empirical_Z ~ predicted_Z)
R2 = round(summary(fit)$r.squared,2)
subtitle = paste("R2 = ",R2)
data = as.data.frame(cbind(predicted_Z, empirical_Z))
ggplot(data, aes(x = predicted_Z, y = empirical_Z))+
geom_point()+
geom_abline(intercept = 0, slope = 1)+
labs(title = "Observed versus predicted data, sd dataset",
subtitle = subtitle)
summmary(fit)
summaryfit
summary(fit)
library(dplyr)
library(ggplot2)
library(gridExtra)
rm(list = ls())
cat("\014")
plotdata = read.csv("../Data/AllPlotsVarsRichness.csv")
scotswoods = c(38,40,42,47,50,53,56,59,68,74,76,77,98)
allplotdata_scots = plotdata%>%filter(Site%in%scotswoods)
allplotdatae_england = plotdata%>%filter(!Site%in%scotswoods)
## NB - aseveral libraries mask each other here - arm masks dplyr and corrplot, therefore open libraries #as required.
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
# Richness modelling
rm(list = ls())
cat("\014")
library(dplyr) # everything
library(ggplot2)
library(corrplot)
install.packages(corrplot)
install.packages("corrplot")
## NB - aseveral libraries mask each other here - arm masks dplyr and corrplot, therefore open libraries #as required.
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
# Richness modelling
rm(list = ls())
cat("\014")
library(dplyr) # everything
library(ggplot2)
library(corrplot)
library(car) # for vif
library(reshape) # melt
zeta_r = readRDS("../Zeta/zeta_r")
# get the data
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
Site = c(1:103)
zeta_r = as.data.frame(cbind(Site,zeta_r))
site_data = inner_join(site_data,zeta_r)
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
# slect only required variables
subset_all = site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity","zeta_r")
library(dplyr) # everything
# slect only required variables
subset_all = site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity","zeta_r")
View(site_data)
## NB - aseveral libraries mask each other here - arm masks dplyr and corrplot, therefore open libraries #as required.
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
# Richness modelling
rm(list = ls())
cat("\014")
library(dplyr) # everything
library(ggplot2)
library(corrplot)
library(car) # for vif
library(reshape) # melt
zeta_r = readRDS("../Zeta/zeta_r")
# get the data
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
Site = c(1:103)
zeta_r = as.data.frame(cbind(Site,zeta_r))
site_data = inner_join(site_data,zeta_r)
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
# slect only required variables
subset_all = site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity","zeta_r")
View(site_data)
site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity","zeta_r")
subset_all = site_data%>%select(Site,Richness,Area_ha,
Northing, Pos_Hetero_Index,Buffer3,
no_MSG, no_NVC,sd_pH,sd_SOM)
# slect only required variables
subset_all = site_data%>%select(Site,Richness,Area_ha,
Northing, Pos_Hetero_Index,Buffer3,
no_MSG, no_NVC,sd_pH,sd_SOM,sd_LBA,
sd_meandbh,sd_treedensity,area_ratio,
meandbh,meanph, meanSOM,meanLBA,
meantreedensity,zeta_r)
colnames(subset_all) = c("Site","Richness","Area",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD","zeta_r")
subset_sd = site_data_outlier%>%select(Site,Richness,
PHI,Buffer,Northing,
no_MSG, no_NVC,sd_pH,sd_SOM,sd_LBA,
sd_meandbh,sd_TD,area_ratio,zeta_r)
#remove the wood with the largest area
largest_area = as.numeric(subset_all%>%filter(Area == max(Area))%>%select(Site))
site_data_outlier = subset_all%>%filter(Site!=largest_area)
site_data_outlier = site_data_outlier[,-3] # remove area column now
subset_sd = site_data_outlier%>%select(Site,Richness,
PHI,Buffer,Northing,
no_MSG, no_NVC,sd_pH,sd_SOM,sd_LBA,
sd_meandbh,sd_TD,area_ratio,zeta_r)
#,
subset_mean = site_data_outlier%>%select("Site","Richness",
"PHI", "Northing", "meandbh","Buffer",
"meanph",  "meanSOM","meanLBA",
"meanTD","area_ratio", "no_NVC",
"no_MSG","zeta_r")
subset_sd = site_data_outlier%>%select(Site,Richness,
PHI,Buffer,Northing,
no_MSG, no_NVC,sd_pH,sd_SOM,sd_LBA,
sd_meandbh,sd_TD,area_ratio,zeta_r)
#,
subset_mean = site_data_outlier%>%select(Site,Richness,
PHI, Northing, meandbh,Buffer,
meanph,  meanSOM,mean,no_NVC,
no_MSG,zeta_r)
subset_sd = site_data_outlier%>%select(Site,Richness,
PHI,Buffer,Northing,
no_MSG, no_NVC,sd_pH,sd_SOM,sd_LBA,
sd_meandbh,sd_TD,area_ratio,zeta_r)
#,
subset_mean = site_data_outlier%>%select(Site,Richness,
PHI, Northing, meandbh,Buffer,
meanph,  meanSOM,meanTD,meanLBA, no_NVC,
no_MSG,zeta_r)
#,
#rescale the mean data
library(arm) #for standarize
install.packages("arm")
subset_sd = site_data_outlier%>%select(Site,Richness,
PHI,Buffer,Northing,
no_MSG, no_NVC,sd_pH,sd_SOM,sd_LBA,
sd_meandbh,sd_TD,area_ratio,zeta_r)
#,
subset_mean = site_data_outlier%>%select(Site,Richness,
PHI, Northing, meandbh,Buffer,
meanph,  meanSOM,meanTD,meanLBA, area_ratio,no_NVC,
no_MSG,zeta_r)
#,
#rescale the mean data
library(arm) #for standarize
rescaled_mean_data = apply(data[,-1],2, rescale)
##Models for means#############
# we know richness vs ph usually unimodal around .5, therefore fit to meanpH^2
data = subset_mean[,-1]
richness = subset_mean[,2] # removed because going to scale in next chunk
#data$meanph2 = (data$meanph)^2 #just leave as meanpH because doesnt come out either way??
#dont do this because meanpH and meanpH2 correlated and messes it all up. Just accept that model wont select mean pH very well
#rescale the mean data
library(arm) #for standarize
rescaled_mean_data = apply(data[,-1],2, rescale)
rescaled_mean_data = as.data.frame(cbind(richness, rescaled_mean_data))
#rescale the SD data
data = subset_sd[,-1]
richness = subset_sd[,2]
rescaled_sd_data = apply(data[,-1],2, rescale)
rescaled_sd_data = as.data.frame(cbind(richness, rescaled_sd_data))
#create the model
mod_mean = lm(richness~., data=rescaled_mean_data, na.action = "na.fail")
#create the model
mod_mean = lm(richness~., data=rescaled_mean_data, na.action = "na.fail")
#create the model
mod_sd = lm(richness~., data=rescaled_sd_data, na.action = "na.fail")
mod_sd = lm(richness~., data=rescaled_sd_data, na.action = "na.fail")
install.packages("MuMin")
install.packages("MuMIn")
library(MuMIn) #dredge and avg
#get top models
models = dredge(mod_mean)
model_set = get.models(models, subset = delta<2)
#do model averaging, subset means zero method
mean_avg_models = model.avg(model_set, subset)
#select output data
summary = summary(mean_avg_models)
coefs =  mean_avg_models$coefficients
importance =  c(NA,(as.vector(mean_avg_models$importance)))
coef_matrix = summary$coefmat.full
coefs = coef_matrix[,1]
adj_se = coef_matrix[,3]
CI_lower =  coefs - 1.96*adj_se
CI_upper = coefs + 1.96*adj_se
output = round(as.data.frame(cbind(coefs,adj_se, CI_lower, CI_upper, importance)),2)
# make plot of the variables and CI
n = nrow(output)
data = output[c(2:n),]
data = data[,c(1,3,4)]
data = t(data)
data = as.data.frame(data)
melted = melt(data)
fun_mean <- function(x){
data = data.frame(y=mean(x),label=mean(x,na.rm=T))
data = round(data,2)
return(data)}
#(aes_string(x = 'variable', y='value', na.rm = TRUE)
melted$variable = as.factor(melted$variable)# ps, wont plot as separate plots if x continous
ggplot(melted,aes_string(x = 'variable', y ='value' ) )+
geom_boxplot(na.rm = TRUE, width = 0)+
stat_summary(fun.y = mean, geom="point",colour="darkred", size=3) +
stat_summary(fun.data = fun_mean, geom="text", vjust=-0.7)+
stat_summary(geom = "text", label = output$importance[-1],fun.y = max, hjust = 1, colour = "red")+
geom_abline(intercept = 0, slope = 0)+
labs(y = "Effect size and 95%CI",x = "Parameter")+
labs(title = "MEAN dataset" )+
theme(axis.text.x = element_text(angle=45, hjust=1))+
theme(text = element_text(size = 14, face = "bold"))
library(MuMIn) #dredge and avg
#get top models
models = dredge(mod_sd)
model_set = get.models(models, subset = delta<1.99)
#do model averaging, subset means zero method
sd_avg_models = model.avg(model_set, subset)
#select output data
summary = summary(sd_avg_models)
coefs =  sd_avg_models$coefficients
importance =  c(NA,(as.vector(sd_avg_models$importance)))
coef_matrix = summary$coefmat.full
coefs = coef_matrix[,1]
adj_se = coef_matrix[,3]
CI_lower =  coefs - 1.96*adj_se
CI_upper = coefs + 1.96*adj_se
output = round(as.data.frame(cbind(coefs,adj_se, CI_lower, CI_upper, importance)),2)
# make plot of the variables and CI
n = nrow(output)
data = output[c(2:n),]
data = data[,c(1,3,4)]
data = t(data)
data = as.data.frame(data)
melted = melt(data)
fun_mean <- function(x){
data = data.frame(y=mean(x),label=mean(x,na.rm=T))
data = round(data,2)
return(data)}
#(aes_string(x = 'variable', y='value', na.rm = TRUE)
melted$variable = as.factor(melted$variable)# ps, wont plot as separate plots if x continous
ggplot(melted,aes_string(x = 'variable', y ='value' ) )+
geom_boxplot(na.rm = TRUE, width = 0)+
stat_summary(fun.y = mean, geom="point",colour="darkred", size=3) +
stat_summary(fun.data = fun_mean, geom="text", vjust=-0.7)+
stat_summary(geom = "text", label = output$importance[-1],fun.y = max, hjust = 1, colour = "red")+
geom_abline(intercept = 0, slope = 0)+
labs(y = "Effect size and 95%CI",x = "Parameter", face = "bold")+
labs(title = "STANDARD DEVIATION dataset" )+
theme(axis.text.x = element_text(angle=45, hjust=1))+
theme(text = element_text(size = 14, face = "bold"))
rm(list = ls())
cat("\014")
library(dplyr)
library(rpart)
library(rpart.plot)
library(gbm)#bgm
library(caret)
library(Metrics) #rmse
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
zeta_r = readRDS("../Zeta/zeta_r")
Site = c(1:103)
zeta_r = as.data.frame(cbind(Site,zeta_r))
site_data = inner_join(zeta_r,site_data)
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
subset_all = site_data%>%select(Site,Richness,Area_ha,
Northing, Pos_Hetero_Index,Buffer3,
no_MSG, no_NVC,sd_pH,sd_SOM,sd_LBA,
sd_meandbh,sd_treedensity,area_ratio,
meandbh,meanph, meanSOM,meanLBA,
meantreedensity,zeta_r)
