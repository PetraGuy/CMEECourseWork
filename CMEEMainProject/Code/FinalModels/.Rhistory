# get the data
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
# slect only required variables
subset_all = site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity")
## NB - aseveral libraries mask each other here - arm masks dplyr and corrplot, therefore open libraries #as required.
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
# Richness modelling
rm(list = ls())
cat("\014")
library(dplyr) # everything
library(ggplot2)
library(corrplot)
library(car) # for vif
library(reshape) # melt
zeta_r = readRDS("../Zeta/zeta_r")
# get the data
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
# slect only required variables
subset_all = site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity")
colnames(subset_all) = c("Site","Richness","Area",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD")
#remove the wood with the largest area
largest_area = as.numeric(subset_all%>%filter(Area == max(Area))%>%select(Site))
site_data_outlier = subset_all%>%filter(Site!=largest_area)
site_data_outlier = site_data_outlier[,-3] # remove area column now
subset_sd = site_data_outlier%>%select("Site","Richness",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio")
subset_mean = site_data_outlier%>%select("Site","Richness",
"Northing", "PHI",  "meandbh",
"meanph", "Buffer", "meanSOM","meanLBA",
"meanTD","area_ratio", "no_NVC",
"no_MSG")
#look at correaltions between explanatory variables
vars = site_data_outlier[,-c(1,2)]
mcor = round(cor(vars, method = "pearson", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 0.5, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "pearson correlation",
mar=c(0,0,1,0))
mcor = round(cor(vars, method = "spearman", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 0.5, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "spearman correlation",
mar=c(0,0,1,0))
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 0.5, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "spearman correlation",
mar=c(0,0,1,0))
###Means correlations...
library(corrplot)
vars = subset_mean[,-c(1,2)]
mcor = round(cor(vars, method = "pearson", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 1, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "mean dataset pearson correlation",
number.cex = 1,
mar=c(0,0,1,0))
mcor = round(cor(vars, method = "spearman", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 1, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "mean dataset spearman correlation",
number.cex = 1,
mar=c(0,0,1,0))
###SD correlations...
library(corrplot)
vars = subset_sd[,-c(1,2)]
mcor = round(cor(vars, method = "pearson", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 1, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "SD pearson correlation",
mar=c(0,0,1,0))
mcor = round(cor(vars, method = "spearman", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 1, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "SD spearman correlation",
mar=c(0,0,1,0))
## NB - aseveral libraries mask each other here - arm masks dplyr and corrplot, therefore open libraries #as required.
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
# Richness modelling
rm(list = ls())
cat("\014")
library(dplyr) # everything
library(ggplot2)
library(corrplot)
library(car) # for vif
library(reshape) # melt
zeta_r = readRDS("../Zeta/zeta_r")
# get the data
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
# slect only required variables
subset_all = site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity")
colnames(subset_all) = c("Site","Richness","Area",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD")
#remove the wood with the largest area
largest_area = as.numeric(subset_all%>%filter(Area == max(Area))%>%select(Site))
site_data_outlier = subset_all%>%filter(Site!=largest_area)
site_data_outlier = site_data_outlier[,-3] # remove area column now
subset_sd = site_data_outlier%>%select("Site","Richness",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio")
subset_mean = site_data_outlier%>%select("Site","Richness",
"Northing", "PHI",  "meandbh",
"meanph", "Buffer", "meanSOM","meanLBA",
"meanTD","area_ratio", "no_NVC",
"no_MSG")
#look at correaltions between explanatory variables
vars = site_data_outlier[,-c(1,2)]
mcor = round(cor(vars, method = "pearson", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 0.5, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "pearson correlation",
mar=c(0,0,1,0))
mcor = round(cor(vars, method = "spearman", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 0.5, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "spearman correlation",
mar=c(0,0,1,0))
###Means correlations...
library(corrplot)
vars = subset_mean[,-c(1,2)]
mcor = round(cor(vars, method = "pearson", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 1, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "mean dataset pearson correlation",
number.cex = 1,
mar=c(0,0,1,0))
mcor = round(cor(vars, method = "spearman", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 1, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "mean dataset spearman correlation",
number.cex = 1,
mar=c(0,0,1,0))
##Models for means#############
# we know richness vs ph usually unimodal around .5, therefore fit to meanpH^2
data = subset_mean[,-1]
richness = subset_mean[,2]
data$meanph = (data$meanph)^2
#rescale the mean data
library(arm) #for standarize
rescaled_mean_data = apply(data[,-1],2, rescale)
rescaled_mean_data = as.data.frame(cbind(richness, rescaled_mean_data))
#rescale the SD data
data = subset_sd[,-1]
richness = subset_sd[,2]
rescaled_sd_data = apply(data[,-1],2, rescale)
rescaled_sd_data = as.data.frame(cbind(richness, rescaled_sd_data))
#create the model
mod_mean = lm(richness~., data=rescaled_mean_data, na.action = "na.fail")
#create the model
mod_sd = lm(richness~., data=rescaled_sd_data, na.action = "na.fail")
library(MuMIn) #dredge and avg
#get top models
models = dredge(mod_mean)
model_set = get.models(models, subset = delta<2)
#do model averaging, subset means zero method
mean_avg_models = model.avg(model_set, subset)
#select output data
summary = summary(mean_avg_models)
coefs =  mean_avg_models$coefficients
importance =  c(NA,(as.vector(mean_avg_models$importance[1:8])))
coef_matrix = summary$coefmat.full
coefs = coef_matrix[,1]
adj_se = coef_matrix[,3]
CI_lower =  coefs - 1.96*adj_se
CI_upper = coefs + 1.96*adj_se
output = round(as.data.frame(cbind(coefs,adj_se, CI_lower, CI_upper, importance)),2)
model_set
models
knitr::opts_chunk$set(echo = FALSE)
rm(list = ls())
cat("\014")
library(dplyr)
library(rpart)
library(rpart.plot)
library(gbm)#bgm
library(caret)
library(Metrics) #rmse
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
zeta_r = readRDS("../Zeta/zeta_r")
Site = c(1:103)
zeta_r = as.data.frame(cbind(Site,zeta_r))
site_data = inner_join(zeta_r,site_data)
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
subset_all = site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity","zeta_r")
rm(list = ls())
cat("\014")
library(dplyr)
library(rpart)
library(rpart.plot)
library(gbm)#bgm
library(caret)
library(Metrics) #rmse
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
zeta_r = readRDS("../Zeta/zeta_r")
Site = c(1:103)
zeta_r = as.data.frame(cbind(Site,zeta_r))
site_data = inner_join(zeta_r,site_data)
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
subset_all = site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity","zeta_r")
colnames(subset_all) = c("Site","Richness","Area",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD","zeta_r")
subset_sd = subset_all%>%select("Richness",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"zeta_r")
subset_mean = subset_all%>%select("Richness",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD","zeta_r")
get_rmse = function(model,traintest){
rmses = list()
trainset = traintest[[1]]
testset = traintest[[2]]
ntree_opt = gbm.perf(model, method = "cv",oobag.curve = FALSE)
pred_train = predict(model,trainset, ntree_opt)
pred_test <- predict(model,testset,ntree_opt)
rmses[[1]] = rmse(actual = trainset$Richness, predicted = pred_train)
rmses[[2]] = rmse(actual = testset$Richness,   predicted = pred_test)
return(rmses)
}
get_rel_infl = function(model){
s = summary(model,n.trees=10000)
x = as.character(s$var)
y = s$rel.inf
data = as.data.frame(cbind(x,y))
data$y = as.numeric(levels(data$y))[data$y]
data$x <- factor(data$x, levels = data$x[order(data$y)])
return(data)
}
get_influence = function(datasubset,relinfl) {
vars = colnames(datasubset[-1])
ris = vector()
for (var in vars){
ris[var] = as.vector(filter(relinfl,relinfl$x == var)[2])
}
return(ris)
}
add_list_elements = function(list1,list2){
list_sum = list()
length = length(list1)
for (i in 1:length){
list_sum[[i]] = list1[[i]]+list2[[i]]
}
return(list_sum)
}
run_boosted_bootstrap = function(dataset){
#browser()
# initialise
data = list()
rmse_list = list()
rmse_list[[1]] = 0
rmse_list[[2]] = 0
#initalise a list for rel imp
rel_infl_list = list()
for (i in 1:ncol(dataset[-1])){
rel_infl_list[i] = 0
}
for (i in 1:100){
data = get_traintest(dataset)
model = get_model(data)
rmse_train = get_rmse(model,data)[[1]]
rmse_test = get_rmse(model,data)[[2]]
rmse_list[[1]] = rmse_list[[1]] + rmse_train
rmse_list[[2]] = rmse_list[[2]] + rmse_test
rel_infl = get_rel_infl(model)
rel_infl_ordered = get_influence(dataset,rel_infl)
rel_infl_list = add_list_elements(rel_infl_list,rel_infl_ordered)
}
variables = colnames(dataset[-1])
relinlf_df = data.frame(rel_influence = length(variables))
#initalise a list for rel imp
rel_infl_list = list()
for (i in 1:ncol(dataset[-1])){
rel_infl_list[i] = 0
}
for (i in 1:100){
data = get_traintest(dataset)
model = get_model(data)
rmse_train = get_rmse(model,data)[[1]]
rmse_test = get_rmse(model,data)[[2]]
rmse_list[[1]] = rmse_list[[1]] + rmse_train
rmse_list[[2]] = rmse_list[[2]] + rmse_test
rel_infl = get_rel_infl(model)
rel_infl_ordered = get_influence(dataset,rel_infl)
rel_infl_list = add_list_elements(rel_infl_list,rel_infl_ordered)
}
variables = colnames(dataset[-1])
relinlf_df = data.frame(rel_influence = length(variables))
for (i in 1:ncol(dataset[-1])){
relinlf_df[i,1] = rel_infl_list[[i]]/100
}
relinlf_df = as.data.frame(cbind(variables,relinlf_df))
rmse_train_set = round(rmse_list[[1]]/100,2)
rmse_test_set = round(rmse_list[[2]]/100,2)
knitr::opts_chunk$set(echo = FALSE)
rm(list = ls())
cat("\014")
library(dplyr)
library(rpart)
library(rpart.plot)
library(gbm)#bgm
library(caret)
library(Metrics) #rmse
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
zeta_r = readRDS("../Zeta/zeta_r")
Site = c(1:103)
zeta_r = as.data.frame(cbind(Site,zeta_r))
site_data = inner_join(zeta_r,site_data)
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
subset_all = site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity","zeta_r")
colnames(subset_all) = c("Site","Richness","Area",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD","zeta_r")
knitr::opts_chunk$set(echo = FALSE)
rm(list = ls())
cat("\014")
library(dplyr)
library(rpart)
library(rpart.plot)
library(gbm)#bgm
library(caret)
library(Metrics) #rmse
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
zeta_r = readRDS("../Zeta/zeta_r")
Site = c(1:103)
zeta_r = as.data.frame(cbind(Site,zeta_r))
site_data = inner_join(zeta_r,site_data)
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
subset_all = site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity","zeta_r")
colnames(subset_all) = c("Site","Richness","Area",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD","zeta_r")
subset_sd = subset_all%>%select("Richness",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"zeta_r")
subset_mean = subset_all%>%select("Richness",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD","zeta_r")
#OK, lets try that then
model = gbm(formula = Richness~.,
data = subset_mean,
n.minobsinnode = 2,
bag.fraction = 0.8 ,
interaction.depth =6,
n.trees = 10000,
distribution = "gaussian",
cv.folds =5)
print( model$train.error[length(model$train.error)])
pred <- predict(model,subset_mean,10000)
rmse(actual = subset_mean$Richness,
predicted = pred)
summary(model,n.trees=10000)
#now need a train and test set  MEANS START HERE
#set.seed(5)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.7,0.3), replace = TRUE)
train <- subset_mean[assignment == 1, ]
test <- subset_mean[assignment == 2, ]
#run model on train set
model = gbm(formula = Richness~.,
data = train,
n.minobsinnode = 2,
bag.fraction = 0.8 ,
interaction.depth = 6,
n.trees = 10000,
distribution = "gaussian",
cv.folds =5)
#print( model$train.error[length(model$train.error)])
ntree_opt_oob = gbm.perf(model, method = "cv",oobag.curve = TRUE)
pred_test <- predict(model,test,ntree_opt_oob)
pred_train = predict(model,train,ntree_opt_oob)
rmse_test = rmse(actual = test$Richness,   predicted = pred_test)
rmse_train = rmse(actual = train$Richness, predicted = pred_train)
rmse_test
rmse_train
#print( model$train.error[length(model$train.error)])
ntree_opt_oob = gbm.perf(model, method = "cv",oobag.curve = TRUE)
#run model on train set
model = gbm(formula = Richness~.,
data = train,
n.minobsinnode = 2,
bag.fraction = 0.8 ,
interaction.depth = 6,
n.trees = 3500,
distribution = "gaussian",
cv.folds =5)
#print( model$train.error[length(model$train.error)])
ntree_opt_oob = gbm.perf(model, method = "cv",oobag.curve = TRUE)
pred_test <- predict(model,test,ntree_opt_oob)
pred_train = predict(model,train,ntree_opt_oob)
rmse_test = rmse(actual = test$Richness,   predicted = pred_test)
rmse_train = rmse(actual = train$Richness, predicted = pred_train)
rmse_test
rmse_train
