mean_avg_models = model.avg(model_set, subset)
#select output data
summary = summary(mean_avg_models)
coefs =  mean_avg_models$coefficients
importance =  c(NA,(as.vector(mean_avg_models$importance)))
coef_matrix = summary$coefmat.full
coefs = coef_matrix[,1]
adj_se = coef_matrix[,3]
CI_lower =  coefs - 1.96*adj_se
CI_upper = coefs + 1.96*adj_se
output = round(as.data.frame(cbind(coefs,adj_se, CI_lower, CI_upper, importance)),2)
# make plot of the variables and CI
n = nrow(output)
data = output[c(2:n),]
data = data[,c(1,3,4)]
data = t(data)
data = as.data.frame(data)
melted = melt(data)
fun_mean <- function(x){
data = data.frame(y=mean(x),label=mean(x,na.rm=T))
data = round(data,2)
return(data)}
#(aes_string(x = 'variable', y='value', na.rm = TRUE)
melted$variable = as.factor(melted$variable)# ps, wont plot as separate plots if x continous
ggplot(melted,aes_string(x = 'variable', y ='value' ) )+
geom_boxplot(na.rm = TRUE, width = 0)+
stat_summary(fun.y = mean, geom="point",colour="darkred", size=3) +
stat_summary(fun.data = fun_mean, geom="text", vjust=-0.7)+
stat_summary(geom = "text", label = output$importance[-1],fun.y = max, hjust = 1, colour = "red")+
geom_abline(intercept = 0, slope = 0)+
labs(y = "Parameter estimate and 95%CI",x = "Parameter")+
labs(title = "Model averaged results for delta <2, mean dataset",
subtitle = "Numbers in red are importance")
library(MuMIn) #dredge and avg
#get top models
models = dredge(mod_sd)
model_set = get.models(models, subset = delta<1.99)
#do model averaging, subset means zero method
sd_avg_models = model.avg(model_set, subset)
#select output data
summary = summary(sd_avg_models)
coefs =  sd_avg_models$coefficients
importance =  c(NA,(as.vector(sd_avg_models$importance)))
coef_matrix = summary$coefmat.full
coefs = coef_matrix[,1]
adj_se = coef_matrix[,3]
CI_lower =  coefs - 1.96*adj_se
CI_upper = coefs + 1.96*adj_se
output = round(as.data.frame(cbind(coefs,adj_se, CI_lower, CI_upper, importance)),2)
# make plot of the variables and CI
n = nrow(output)
data = output[c(2:n),]
data = data[,c(1,3,4)]
data = t(data)
data = as.data.frame(data)
melted = melt(data)
fun_mean <- function(x){
data = data.frame(y=mean(x),label=mean(x,na.rm=T))
data = round(data,2)
return(data)}
#(aes_string(x = 'variable', y='value', na.rm = TRUE)
melted$variable = as.factor(melted$variable)# ps, wont plot as separate plots if x continous
ggplot(melted,aes_string(x = 'variable', y ='value' ) )+
geom_boxplot(na.rm = TRUE, width = 0)+
stat_summary(fun.y = mean, geom="point",colour="darkred", size=3) +
stat_summary(fun.data = fun_mean, geom="text", vjust=-0.7)+
stat_summary(geom = "text", label = output$importance[-1],fun.y = max, hjust = 1, colour = "red")+
geom_abline(intercept = 0, slope = 0)+
labs(y = "Parameter estimate and 95%CI",x = "Parameter")+
labs(title = "Model averaged results for delta <2, standard deviation dataset",
subtitle = "Numbers in red are importance")
summary(mean_avg_models)
mean_avg_models
#extract model averaged parameter estimates
predicted_richness = predict(mean_avg_models, full = TRUE)
empirical_richness =  site_data_outlier$Richness
fit = lm(empirical_richness ~ predicted_richness)
R2 = round(summary(fit)$r.squared,2)
f = summary(fit)$fstatistic
p = round(pf(f[1],f[2],f[3], lower.tail = F),4)
rmse = round(rmse(actual = empirical_richness, predicted =  predicted_richness),2)
subtitle = paste("R2 = ",R2, "p = ",p, "rmse = ", rmse)
data = as.data.frame(cbind(predicted_richness, empirical_richness))
ggplot(data, aes(x = predicted_richness, y = empirical_richness))+
geom_point()+
geom_abline(intercept = 0, slope = 1)+
labs(title = "Observed versus predicted data, mean dataset",
subtitle = subtitle)
summary(fit)
## NB - aseveral libraries mask each other here - arm masks dplyr and corrplot, therefore open libraries #as required.
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
# Richness modelling
rm(list = ls())
cat("\014")
library(dplyr) # everything
library(ggplot2)
library(car) # for vif
library(reshape) # melt
# get the data
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
nestZs = readRDS("../nest_mixed_model_fits.RDS")
Zs = nestZs%>%select(Site,slope)
## NB - aseveral libraries mask each other here - arm masks dplyr and corrplot, therefore open libraries #as required.
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
# Richness modelling
rm(list = ls())
cat("\014")
library(dplyr) # everything
library(ggplot2)
library(car) # for vif
library(reshape) # melt
# get the data
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
nestZs = readRDS("../nest_mixed_model_fits.RDS")
Zs = nestZs%>%select(Site,slope)
zeta_r = readRDS("../Zeta/zeta_r")
Site = c(1:103)
zeta_r = as.data.frame(cbind(Site,zeta_r))
site_data = inner_join(site_data,zeta_r)
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
site_data_zs = inner_join(site_data,Zs)
# slect only required variables
subset_all = site_data_zs%>%select("Site","slope","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity","zeta_r")
colnames(subset_all) = c("Site","nestZ","Area",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD","zeta_r")
#remove the wood with the largest area
largest_area = as.numeric(subset_all%>%filter(Area == max(Area))%>%select(Site))
site_data_outlier1 = subset_all%>%filter(Site!=largest_area)
site_data_outlier1 = site_data_outlier1[,-3] # remove area column now
#remove the outlier in PHI
largest_PHI = as.numeric(subset_all%>%filter(PHI == max(PHI))%>%select(Site))
site_data_outlier2 = site_data_outlier1%>%filter(Site!=largest_PHI)
largest_PHI = as.numeric(site_data_outlier2%>%filter(PHI == max(PHI))%>%select(Site))
site_data_outlier3 = site_data_outlier2%>%filter(Site!=largest_PHI)
subset_sd = site_data_outlier3%>%select("Site","nestZ",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio","zeta_r")
subset_mean = site_data_outlier3%>%select("Site","nestZ",
"Northing", "PHI",  "meandbh",
"meanph", "Buffer", "meanSOM","meanLBA",
"meanTD","area_ratio", "no_NVC",
"no_MSG","zeta_r")
# we know richness vs ph usually unimodal around .5, therefore fit to meanpH^2
data = subset_sd[,-1]
nestZ = subset_mean[,2]
#rescale the data
library(arm) #for standarize
rescaled_sd_data = apply(data[,-1],2, rescale)
rescaled_sd_data = as.data.frame(cbind(nestZ, rescaled_sd_data))
#create the model
mod_sd = lm(nestZ~., data=rescaled_sd_data, na.action = "na.fail")
library(MuMIn) #dredge and avg
#get top models
models = dredge(mod_mean)
## NB - aseveral libraries mask each other here - arm masks dplyr and corrplot, therefore open libraries #as required.
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
# Richness modelling
rm(list = ls())
cat("\014")
library(dplyr) # everything
library(ggplot2)
library(corrplot)
library(car) # for vif
library(reshape) # melt
zeta_r = readRDS("../Zeta/zeta_r")
# get the data
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
Site = c(1:103)
zeta_r = as.data.frame(cbind(Site,zeta_r))
site_data = inner_join(site_data,zeta_r)
View(site_data)
rm(list = ls())
cat("\014")
library(dplyr) # everything
library(ggplot2)
library(corrplot)
library(car) # for vif
library(reshape) # melt
zeta_r = readRDS("../Zeta/zeta_r")
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
Site = c(1:103)
zeta_r = as.data.frame(cbind(Site,zeta_r))
site_data = inner_join(site_data,zeta_r)
View(site_data)
View(site_data)
subset_all = site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity","zeta_r")
colnames(subset_all) = c("Site","Richness","Area",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD","zeta_r")
subset_sd = site_data_outlier%>%select("Site","Richness",
"PHI","Buffer","Northing",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio","zeta_r")
vars = site_data_outlier[,-c(1,2)]
mcor = round(cor(vars, method = "pearson", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 0.5, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "pearson correlation",
mar=c(0,0,1,0))
mcor = round(cor(vars, method = "spearman", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 0.5, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "spearman correlation",
mar=c(0,0,1,0))
largest_area = as.numeric(subset_all%>%filter(Area == max(Area))%>%select(Site))
site_data_outlier = subset_all%>%filter(Site!=largest_area)
site_data_outlier = site_data_outlier[,-3]
vars = site_data_outlier[,-c(1,2)]
mcor = round(cor(vars, method = "pearson", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 0.5, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "pearson correlation",
mar=c(0,0,1,0))
mcor = round(cor(vars, method = "spearman", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 0.5, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "spearman correlation",
mar=c(0,0,1,0))
library(corrplot)
vars = subset_sd[,-c(1,2)]
mcor = round(cor(vars, method = "pearson", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 1, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "SD pearson correlation",
mar=c(0,0,1,0))
mcor = round(cor(vars, method = "spearman", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 1, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "SD spearman correlation",
mar=c(0,0,1,0))
mcor = round(cor(vars, method = "pearson", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 1, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "SD pearson correlation",
mar=c(0,0,1,0))
vars = subset_sd[,-c(1,2)]
mcor = round(cor(vars, method = "pearson", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 1, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "SD pearson correlation",
mar=c(0,0,1,0))
mcor = round(cor(vars, method = "spearman", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 1, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "SD spearman correlation",
mar=c(0,0,1,0))
subset_sd = site_data_outlier%>%select("Site","Richness",
"PHI","Buffer","Northing",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio","zeta_r")
vars = subset_sd[,-c(1,2)]
mcor = round(cor(vars, method = "pearson", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 1, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "SD pearson correlation",
mar=c(0,0,1,0))
mcor = round(cor(vars, method = "spearman", use = "na.or.complete"),2)
corrplot(mcor, type = "upper", tl.pos = "td",
method = "number", tl.cex = 1, tl.col = 'black',tl.srt=45,
order = "hclust", diag = FALSE,
title = "SD spearman correlation",
mar=c(0,0,1,0))
knitr::opts_chunk$set(echo = FALSE)
rm(list = ls())
cat("\014")
library(dplyr)
library(rpart)
library(rpart.plot)
library(gbm)#bgm
library(caret)
library(Metrics) #rmse
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
zeta_r = readRDS("../Zeta/zeta_r")
Site = c(1:103)
zeta_r = as.data.frame(cbind(Site,zeta_r))
site_data = inner_join(zeta_r,site_data)
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
subset_all = site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity","zeta_r")
colnames(subset_all) = c("Site","Richness","Area",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD","zeta_r")
subset_sd = subset_all%>%select("Richness",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"zeta_r")
subset_mean = subset_all%>%select("Richness",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD","zeta_r")
#now need a train and test set  MEANS START HERE
#set.seed(5)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.7,0.3), replace = TRUE)
train <- subset_mean[assignment == 1, ]
test <- subset_mean[assignment == 2, ]
#run model on train set
model = gbm(formula = Richness~.,
data = train,
n.minobsinnode = 2,
bag.fraction = 0.8 ,
interaction.depth = 6,
n.trees = 10000,
distribution = "gaussian",
cv.folds =5)
#print( model$train.error[length(model$train.error)])
ntree_opt_oob = gbm.perf(model, method = "cv",oobag.curve = TRUE)
pred_test <- predict(model,test,ntree_opt_oob)
pred_train = predict(model,train,ntree_opt_oob)
rmse_test = rmse(actual = test$Richness,   predicted = pred_test)
rmse_train = rmse(actual = train$Richness, predicted = pred_train)
rmse_test
rmse_train
s = summary(model,n.trees=10000)
x = as.character(s$var)
y = s$rel.inf
data = as.data.frame(cbind(x,y))
data$y = as.numeric(levels(data$y))[data$y]
data$x <- factor(data$x, levels = data$x[order(data$y)])
ggplot(data =data , aes(x = x, y = y)) +  geom_bar(stat = "identity")+
ylab("relative influence")+
xlab("")+
theme(axis.text.x=element_text(angle = 45, hjust = 1))
rm(list = ls())
cat("\014")
library(dplyr)
library(rpart)
library(rpart.plot)
library(gbm)#bgm
library(caret)
library(Metrics) #rmse
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
zeta_r = readRDS("../Zeta/zeta_r")
Site = c(1:103)
zeta_r = as.data.frame(cbind(Site,zeta_r))
site_data = inner_join(zeta_r,site_data)
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
subset_all = site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity","zeta_r")
colnames(subset_all) = c("Site","Richness","Area",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD","zeta_r")
subset_sd = subset_all%>%select("Richness",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"zeta_r")
subset_mean = subset_all%>%select("Richness",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD","zeta_r")
get_traintest = function(datasubset){
#browser()
traintest = list()
assignment <- sample(1:2, size = nrow(datasubset), prob = c(0.7,0.3), replace = TRUE)
traintest[[1]] <- datasubset[assignment == 1, ]
traintest[[2]]  <- datasubset[assignment == 2, ]
return(traintest)
}
get_model = function(traintest){
train = traintest[[1]]
model = gbm(formula = Richness~.,
data = train,
n.minobsinnode = 2,
bag.fraction = 0.8 ,
interaction.depth = 6,
n.trees = 10000,
distribution = "gaussian",
cv.folds =5)
return(model)
}
get_rmse = function(model,traintest){
rmses = list()
trainset = traintest[[1]]
testset = traintest[[2]]
ntree_opt = gbm.perf(model, method = "cv",oobag.curve = FALSE)
pred_train = predict(model,trainset, ntree_opt)
pred_test <- predict(model,testset,ntree_opt)
rmses[[1]] = rmse(actual = trainset$Richness, predicted = pred_train)
rmses[[2]] = rmse(actual = testset$Richness,   predicted = pred_test)
return(rmses)
}
get_rel_infl = function(model){
s = summary(model,n.trees=10000)
x = as.character(s$var)
y = s$rel.inf
data = as.data.frame(cbind(x,y))
data$y = as.numeric(levels(data$y))[data$y]
data$x <- factor(data$x, levels = data$x[order(data$y)])
return(data)
}
get_influence = function(datasubset,relinfl) {
vars = colnames(datasubset[-1])
ris = vector()
for (var in vars){
ris[var] = as.vector(filter(relinfl,relinfl$x == var)[2])
}
return(ris)
}
add_list_elements = function(list1,list2){
list_sum = list()
length = length(list1)
for (i in 1:length){
list_sum[[i]] = list1[[i]]+list2[[i]]
}
return(list_sum)
}
##############################
##############################
run_boosted_bootstrap = function(dataset){
#browser()
# initialise
data = list()
rmse_list = list()
rmse_list[[1]] = 0
rmse_list[[2]] = 0
#initalise a list for rel imp
rel_infl_list = list()
for (i in 1:ncol(dataset[-1])){
rel_infl_list[i] = 0
}
for (i in 1:100){
data = get_traintest(dataset)
model = get_model(data)
rmse_train = get_rmse(model,data)[[1]]
rmse_test = get_rmse(model,data)[[2]]
rmse_list[[1]] = rmse_list[[1]] + rmse_train
rmse_list[[2]] = rmse_list[[2]] + rmse_test
rel_infl = get_rel_infl(model)
rel_infl_ordered = get_influence(dataset,rel_infl)
rel_infl_list = add_list_elements(rel_infl_list,rel_infl_ordered)
}
variables = colnames(dataset[-1])
relinlf_df = data.frame(rel_influence = length(variables))
for (i in 1:ncol(dataset[-1])){
relinlf_df[i,1] = rel_infl_list[[i]]/100
}
relinlf_df = as.data.frame(cbind(variables,relinlf_df))
rmse_train_set = round(rmse_list[[1]]/100,2)
rmse_test_set = round(rmse_list[[2]]/100,2)
