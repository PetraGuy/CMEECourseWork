bag.fraction = 0.7 ,
interaction.depth =6,
n.trees = 10000,
distribution = "gaussian",
cv.folds =5)
print( model$train.error[length(model$train.error)])
pred <- predict(model,test,10000)
rmse(actual = test$Richness,
predicted = pred)
summary(model,n.trees=10000)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
train <- subset_mean[assignment == 1, ]
test <- subset_mean[assignment == 2, ]
#run model on test set
model = gbm(formula = Richness~.,
data = test,
n.minobsinnode = 3,
bag.fraction = 0.7 ,
interaction.depth =6,
n.trees = 10000,
distribution = "gaussian",
cv.folds =5)
print( model$train.error[length(model$train.error)])
pred <- predict(model,test,10000)
rmse(actual = test$Richness,
predicted = pred)
summary(model,n.trees=10000)
knitr::opts_chunk$set(echo = FALSE)
rm(list = ls())
cat("\014")
library(dplyr)
library(rpart)
library(rpart.plot)
library(gbm)#bgm
library(caret)
library(Metrics) #rmse
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
subset_all = site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity")
colnames(subset_all) = c("Site","Richness","Area",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD")
# make train and test sets
set.seed(1)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
knitr::opts_chunk$set(echo = FALSE)
rm(list = ls())
cat("\014")
library(dplyr)
library(rpart)
library(rpart.plot)
library(gbm)#bgm
library(caret)
library(Metrics) #rmse
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
subset_all = site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity")
colnames(subset_all) = c("Site","Richness","Area",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD")
subset_sd = subset_all%>%select("Richness",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio")
subset_mean = subset_all%>%select("Richness",
"Northing", "PHI",  "meandbh",
"meanph", "Buffer", "meanSOM","meanLBA",
"meanTD","area_ratio", "no_NVC",
"no_MSG")
# make train and test sets
set.seed(1)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to validation indices only
#tuning
mtry = seq(2,11,1)
nodesize = seq(2,10,2)
sampsize = nrow(train)*c(0.7,0.8)
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
oob_err = c()
for (i in 1:nrow(hyper_grid)){
# browser()
model = randomForest(formula = Richness~.,
data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i] ,
sampsize = hyper_grid$sampsize[i] )
oob_err[i] = forest_model$mse[length(forest_model$mse)]
}
library(randomForest)
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
rm(list = ls())
cat("\014")
library(dplyr)
library(rpart)
library(rpart.plot)
library(gbm)#bgm
library(caret)
library(Metrics) #rmse
library(randomForest)
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
subset_all = site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity")
colnames(subset_all) = c("Site","Richness","Area",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD")
#tuning
mtry = seq(2,11,1)
nodesize = seq(2,10,2)
sampsize = nrow(train)*c(0.7,0.8)
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
oob_err = c()
for (i in 1:nrow(hyper_grid)){
# browser()
model = randomForest(formula = Richness~.,
data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i] ,
sampsize = hyper_grid$sampsize[i] )
oob_err[i] = forest_model$mse[length(forest_model$mse)]
}
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
rm(list = ls())
cat("\014")
library(dplyr)
library(rpart)
library(rpart.plot)
library(gbm)#bgm
library(caret)
library(Metrics) #rmse
library(randomForest)
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
subset_all = site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity")
colnames(subset_all) = c("Site","Richness","Area",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD")
subset_sd = subset_all%>%select("Richness",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio")
subset_mean = subset_all%>%select("Richness",
"Northing", "PHI",  "meandbh",
"meanph", "Buffer", "meanSOM","meanLBA",
"meanTD","area_ratio", "no_NVC",
"no_MSG")
# make train and test sets
set.seed(1)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to validation indices only
#tuning
mtry = seq(2,11,1)
nodesize = seq(2,10,2)
sampsize = nrow(train)*c(0.7,0.8)
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
oob_err = c()
for (i in 1:nrow(hyper_grid)){
# browser()
model = randomForest(formula = Richness~.,
data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i] ,
sampsize = hyper_grid$sampsize[i] )
oob_err[i] = forest_model$mse[length(forest_model$mse)]
}
#tuning
mtry = seq(2,11,1)
nodesize = seq(2,10,2)
sampsize = nrow(train)*c(0.7,0.8)
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
oob_err = c()
for (i in 1:nrow(hyper_grid)){
# browser()
model = randomForest(formula = Richness~.,
data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i] ,
sampsize = hyper_grid$sampsize[i] )
oob_err[i] = model$mse[length(forest_model$mse)]
}
#tuning
mtry = seq(2,11,1)
nodesize = seq(2,10,2)
sampsize = nrow(train)*c(0.7,0.8)
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
oob_err = c()
for (i in 1:nrow(hyper_grid)){
# browser()
model = randomForest(formula = Richness~.,
data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i] ,
sampsize = hyper_grid$sampsize[i] )
oob_err[i] = model$mse[length(model$mse)]
}
opt_i = which.min(oob_err)
print(hyper_grid[opt_i,])
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = rich_test$Richness,
predicted = pred)
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
importance(forest)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to validation indices only
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
importance(forest)
importance = importance(forest)
importance
importance[,1]
sort(importance[,1])
sort(importance[,1], decreasing = TRUE)
varImpPlot(forest)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to validation indices only
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to validation indices only
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to validation indices only
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
#removing noMSG and area ratio as these keep coming up as negative MSE
subset_mean = subset_all%>%select("Richness",
"Northing", "PHI",  "meandbh",
"meanph", "Buffer", "meanSOM","meanLBA",
"meanTD", "no_NVC")
# make train and test sets
set.seed(1)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to validation indices only
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to validation indices only
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to validation indices only
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
#removing noMSG and area ratio as these keep coming up as negative MSE
#removing northing as we have decided that northing and buffer are the same
subset_mean = subset_all%>%select("Richness",
"Northing", "PHI",  "meandbh",
"meanph",  "meanSOM","meanLBA",
"meanTD", "no_NVC")
# make train and test sets
set.seed(1)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to validation indices only
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
#removing noMSG and area ratio as these keep coming up as negative MSE
#removing northing as we have decided that northing and buffer are the same
subset_mean = subset_all%>%select("Richness",
"PHI",  "meandbh",
"meanph", "Buffer" ,"meanSOM","meanLBA",
"meanTD", "no_NVC")
# make train and test sets
set.seed(1)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to validation indices only
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to valid
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the gr
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to validation indices only
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to validation indices only
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to validation indices only
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 8,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 8,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
# make train and test sets
set.seed(1)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to validation indices only
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to validation indices only
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 8,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
?rando,randomForest
?randomForest
