## NB - aseveral libraries mask each other here - arm masks dplyr and corrplot, therefore open libraries #as required.
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
# Richness modelling
rm(list = ls())
cat("\014")
library(dplyr) # everything
library(ggplot2)
library(car) # for vif
library(reshape) # melt
# get the data
site_data =  read.csv("../Data/CompleteSiteLevelVars.csv")
## NB - aseveral libraries mask each other here - arm masks dplyr and corrplot, therefore open libraries #as required.
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
# Richness modelling
rm(list = ls())
cat("\014")
library(dplyr) # everything
library(ggplot2)
library(car) # for vif
library(reshape) # melt
# get the data
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
Zs = read.csv("../../Data/z_ave_fits.csv")
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
site_data_zs = inner_join(site_data,Zs)
View(site_data_zs)
View(site_data_zs)
View(Zs)
PlotZdata = read.csv("../../Data/z_ave_fits.csv")
## NB - aseveral libraries mask each other here - arm masks dplyr and corrplot, therefore open libraries #as required.
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
# Richness modelling
rm(list = ls())
cat("\014")
library(dplyr) # everything
library(ggplot2)
library(car) # for vif
library(reshape) # melt
# get the data
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
PlotZdata = read.csv("../../Data/z_ave_fits.csv")
Zs = PlotZdata$slope
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
site_data_zs = inner_join(site_data,Zs)
View(PlotZdata)
## NB - aseveral libraries mask each other here - arm masks dplyr and corrplot, therefore open libraries #as required.
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
# Richness modelling
rm(list = ls())
cat("\014")
library(dplyr) # everything
library(ggplot2)
library(car) # for vif
library(reshape) # melt
# get the data
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
PlotZdata = read.csv("../../Data/z_ave_fits.csv")
Zs = PlotZdata%>%select(Site, slope)
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
site_data_zs = inner_join(site_data,Zs)
View(site_data_zs)
# slect only required variables
subset_all = site_data_zs%>%select("Site","slope","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity")
colnames(subset_all) = c("Site","nestZ","Area",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD")
#remove the wood with the largest area
largest_area = as.numeric(subset_all%>%filter(Area == max(Area))%>%select(Site))
site_data_outlier1 = subset_all%>%filter(Site!=largest_area)
site_data_outlier1 = site_data_outlier1[,-3] # remove area column now
#remove the outlier in PHI
largest_PHI = as.numeric(subset_all%>%filter(PHI == max(PHI))%>%select(Site))
site_data_outlier2 = site_data_outlier1%>%filter(Site!=largest_PHI)
largest_PHI = as.numeric(site_data_outlier2%>%filter(PHI == max(PHI))%>%select(Site))
site_data_outlier3 = site_data_outlier2%>%filter(Site!=largest_PHI)
subset_sd = site_data_outlier3%>%select("Site","nestZ",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio")
subset_mean = site_data_outlier3%>%select("Site","nestZ",
"Northing", "PHI",  "meandbh",
"meanph", "Buffer", "meanSOM","meanLBA",
"meanTD","area_ratio", "no_NVC",
"no_MSG")
# we know richness vs ph usually unimodal around .5, therefore fit to meanpH^2
data = subset_mean[,-1]
nestZ = subset_mean[,2]
data$meanph = (data$meanph)^2
#rescale the data
library(arm) #for standarize
rescaled_mean_data = apply(data[,-1],2, rescale)
rescaled_mean_data = as.data.frame(cbind(nestZ, rescaled_mean_data))
#create the model
mod_mean = lm(nestZ~., data=rescaled_mean_data, na.action = "na.fail")
#have a look at the linear model
par(mfrow =c(2,2))
plot(mod_mean, main = "Mean dataset")
# we know richness vs ph usually unimodal around .5, therefore fit to meanpH^2
data = subset_sd[,-1]
nestZ = subset_mean[,2]
#rescale the data
library(arm) #for standarize
rescaled_sd_data = apply(data[,-1],2, rescale)
rescaled_sd_data = as.data.frame(cbind(nestZ, rescaled_sd_data))
#create the model
mod_sd = lm(nestZ~., data=rescaled_sd_data, na.action = "na.fail")
#have a look at the linear model
par(mfrow =c(2,2))
plot(mod_sd, main = "SD dataset")
# look at vifs
vif(mod_mean)
# look at vifs
vif(mod_sd)
library(MuMIn) #dredge and avg
#get top models
models = dredge(mod_mean)
model_set = get.models(models, subset = delta<2)
#do model averaging, subset means zero method
mean_avg_models = model.avg(model_set, subset)
#select output data
summary = summary(mean_avg_models)
coefs =  mean_avg_models$coefficients
importance =  c(NA,(as.vector(mean_avg_models$importance[1:9])))
coef_matrix = summary$coefmat.full
coefs = coef_matrix[,1]
adj_se = coef_matrix[,3]
CI_lower =  coefs - 1.96*adj_se
CI_upper = coefs + 1.96*adj_se
output = round(as.data.frame(cbind(coefs,adj_se, CI_lower, CI_upper, importance)),2)
output
models[c(1:15),]
coefs
mean_avg_models$importance
library(MuMIn) #dredge and avg
#get top models
models = dredge(mod_mean)
model_set = get.models(models, subset = delta<2)
#do model averaging, subset means zero method
mean_avg_models = model.avg(model_set, subset)
#select output data
summary = summary(mean_avg_models)
coefs =  mean_avg_models$coefficients
importance =  c(NA,(as.vector(mean_avg_models$importance[1:8])))
coef_matrix = summary$coefmat.full
coefs = coef_matrix[,1]
adj_se = coef_matrix[,3]
CI_lower =  coefs - 1.96*adj_se
CI_upper = coefs + 1.96*adj_se
output = round(as.data.frame(cbind(coefs,adj_se, CI_lower, CI_upper, importance)),2)
# make plot of the variables and CI
data = output[c(2:9),]
data = data[,c(1,3,4)]
data = t(data)
data = as.data.frame(data)
melted = melt(data)
fun_mean <- function(x){
data = data.frame(y=mean(x),label=mean(x,na.rm=T))
data = round(data,2)
return(data)}
#(aes_string(x = 'variable', y='value', na.rm = TRUE)
melted$variable = as.factor(melted$variable)# ps, wont plot as separate plots if x continous
ggplot(melted,aes_string(x = 'variable', y ='value' ) )+
geom_boxplot(na.rm = TRUE, width = 0)+
stat_summary(fun.y = mean, geom="point",colour="darkred", size=3) +
stat_summary(fun.data = fun_mean, geom="text", vjust=-0.7)+
stat_summary(geom = "text", label = output$importance[-1],fun.y = max, hjust = 1, colour = "red")+
geom_abline(intercept = 0, slope = 0)+
labs(y = "Effect size and 95%CI",x = "effect")+
labs(title = "Model averaged results for delta <2, Nest Zs, Mean dataset",
subtitle = "numbers in red are variable importance")
library(MuMIn) #dredge and avg
#get top models
models = dredge(mod_sd)
model_set = get.models(models, subset = delta<2)
#do model averaging, subset means zero method
sd_avg_models = model.avg(model_set, subset)
#select output data
summary = summary(sd_avg_models)
coefs =  sd_avg_models$coefficients
importance =  c(NA,(as.vector(sd_avg_models$importance[1:8])))
coef_matrix = summary$coefmat.full
coefs = coef_matrix[,1]
adj_se = coef_matrix[,3]
CI_lower =  coefs - 1.96*adj_se
CI_upper = coefs + 1.96*adj_se
output = round(as.data.frame(cbind(coefs,adj_se, CI_lower, CI_upper, importance)),2)
# make plot of the variables and CI
data = output[c(2:9),]
data = data[,c(1,3,4)]
data = t(data)
data = as.data.frame(data)
melted = melt(data)
fun_mean <- function(x){
data = data.frame(y=mean(x),label=mean(x,na.rm=T))
data = round(data,2)
return(data)}
#(aes_string(x = 'variable', y='value', na.rm = TRUE)
melted$variable = as.factor(melted$variable)# ps, wont plot as separate plots if x continous
ggplot(melted,aes_string(x = 'variable', y ='value' ) )+
geom_boxplot(na.rm = TRUE, width = 0)+
stat_summary(fun.y = mean, geom="point",colour="darkred", size=3) +
stat_summary(fun.data = fun_mean, geom="text", vjust=-0.7)+
stat_summary(geom = "text", label = output$importance[-1],fun.y = max, hjust = 1, colour = "red")+
geom_abline(intercept = 0, slope = 0)+
labs(y = "Effect size and 95%CI",x = "effect")+
labs(title = "Model averaged results for delta <2, Nest Zs, SD dataset",
subtitle = "numbers in red are variable importance")
sd_avg_models$importance
output
library(MuMIn) #dredge and avg
#get top models
models = dredge(mod_sd)
model_set = get.models(models, subset = delta<2)
#do model averaging, subset means zero method
sd_avg_models = model.avg(model_set, subset)
#select output data
summary = summary(sd_avg_models)
coefs =  sd_avg_models$coefficients
importance =  c(NA,(as.vector(sd_avg_models$importance[1:5])))
coef_matrix = summary$coefmat.full
coefs = coef_matrix[,1]
adj_se = coef_matrix[,3]
CI_lower =  coefs - 1.96*adj_se
CI_upper = coefs + 1.96*adj_se
output = round(as.data.frame(cbind(coefs,adj_se, CI_lower, CI_upper, importance)),2)
# make plot of the variables and CI
data = output[c(2:6),]
data = data[,c(1,3,4)]
data = t(data)
data = as.data.frame(data)
melted = melt(data)
fun_mean <- function(x){
data = data.frame(y=mean(x),label=mean(x,na.rm=T))
data = round(data,2)
return(data)}
#(aes_string(x = 'variable', y='value', na.rm = TRUE)
melted$variable = as.factor(melted$variable)# ps, wont plot as separate plots if x continous
ggplot(melted,aes_string(x = 'variable', y ='value' ) )+
geom_boxplot(na.rm = TRUE, width = 0)+
stat_summary(fun.y = mean, geom="point",colour="darkred", size=3) +
stat_summary(fun.data = fun_mean, geom="text", vjust=-0.7)+
stat_summary(geom = "text", label = output$importance[-1],fun.y = max, hjust = 1, colour = "red")+
geom_abline(intercept = 0, slope = 0)+
labs(y = "Effect size and 95%CI",x = "effect")+
labs(title = "Model averaged results for delta <2, Nest Zs, SD dataset",
subtitle = "numbers in red are variable importance")
#extract model averaged parameter estimates
predicted_Z = predict(mean_avg_models, full = TRUE)
empirical_Z =  site_data_outlier3$nestZ
fit = lm(empirical_Z ~ predicted_Z)
R2 = round(summary(fit)$r.squared,2)
subtitle = paste("R2 = ",R2)
data = as.data.frame(cbind(predicted_Z, empirical_Z))
ggplot(data, aes(x = predicted_Z, y = empirical_Z))+
geom_point()+
geom_abline(intercept = 0, slope = 1)+
labs(title = "Observed versus predicted data, mean dataset",
subtitle = subtitle)
#extract model averaged parameter estimates
predicted_Z = predict(sd_avg_models, full = TRUE)
empirical_Z =  site_data_outlier3$nestZ
fit = lm(empirical_Z ~ predicted_Z)
R2 = round(summary(fit)$r.squared,2)
subtitle = paste("R2 = ",R2)
data = as.data.frame(cbind(predicted_Z, empirical_Z))
ggplot(data, aes(x = predicted_Z, y = empirical_Z))+
geom_point()+
geom_abline(intercept = 0, slope = 1)+
labs(title = "Observed versus predicted data, sd dataset",
subtitle = subtitle)
nestZs = readRDS("../Code/nest_mixed_model_fits.RDS")
## NB - aseveral libraries mask each other here - arm masks dplyr and corrplot, therefore open libraries #as required.
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
# Richness modelling
rm(list = ls())
cat("\014")
library(dplyr) # everything
library(ggplot2)
library(car) # for vif
library(reshape) # melt
# get the data
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
# slect only required variables
subset_all = site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity")
