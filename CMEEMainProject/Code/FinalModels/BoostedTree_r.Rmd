---
title: "BoosetedTreeModels"
author: "Petra Guy"
date: "17 May 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
rm(list = ls())
cat("\014")
library(dplyr)
library(rpart)
library(rpart.plot)
library(gbm)#bgm
library(caret)
library(Metrics) #rmse
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]

zeta_r = readRDS("../Zeta/zeta_r")
Site = c(1:103)
zeta_r = as.data.frame(cbind(Site,zeta_r))
site_data = inner_join(zeta_r,site_data)

#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x

subset_all = site_data%>%select("Site","Richness","Area_ha",
                                "Northing", "Pos_Hetero_Index","Buffer3",
                                "no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
                                "sd_meandbh","sd_treedensity","area_ratio",
                                "meandbh","meanph", "meanSOM","meanLBA",
                                "meantreedensity","zeta_r")



colnames(subset_all) = c("Site","Richness","Area",
                         "Northing", "PHI","Buffer",
                         "no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
                         "sd_meandbh","sd_TD","area_ratio",
                         "meandbh","meanph", "meanSOM","meanLBA",
                         "meanTD","zeta_r")
```


```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
subset_sd = subset_all%>%select("Richness",
                         "Northing", "PHI","Buffer",
                         "no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
                         "sd_meandbh","sd_TD","area_ratio",
                         "zeta_r")



subset_mean = subset_all%>%select("Richness",
                         "Northing", "PHI","Buffer",
                         "no_MSG", "no_NVC","area_ratio",
                         "meandbh","meanph", "meanSOM","meanLBA",
                         "meanTD","zeta_r")


```



```{r}
#Using bootstrapping and CV but without train an test set (see Kuhn p67)
#Do a by hand tune first to explore what's might happen at the limits

#gbm we can tune:n.trees,interaction.depth,shrinkage,n.minobsinnode


  set.seed(1)
 model = gbm(formula = Richness~.,
              data = subset_mean,
              n.minobsinnode = 5,
              bag.fraction = 0.8 ,
              interaction.depth =5,
               n.trees = 10000,
               distribution = "gaussian",
               cv.folds =5)
print( model$train.error[length(model$train.error)])  


```
```{r}
ntree_opt_oob = gbm.perf(model, method = "cv",oobag.curve = TRUE)
```


```{r}
pred <- predict(model,subset_mean,3000)
rmse(actual = subset_mean$Richness,
     predicted = pred)
```

```{r}
summary(model,n.trees=3000)
```



```{r}
#redo above in a loop

nodes  = seq(2,10,1)
idepth = seq(2,6,1)
bag = seq(0.5,0.8,0.1)
hyper_grid = expand.grid(nodes = nodes, bag = bag, idepth = idepth)

oob_err = c()

for (i in 1:nrow(hyper_grid)){
 # browser()
  set.seed(1)
 model = gbm(formula = Richness~.,
              data = subset_mean,
              n.minobsinnode = hyper_grid$nodes[i],
              bag.fraction = hyper_grid$bag[i] ,
              interaction.depth =hyper_grid$idepth[i[]],
               n.trees = 10000,
               distribution = "gaussian",
               cv.folds =5)

oob_err[i] = model$train.error[length(model$train.error)]
  
 }

opt_i = which.min(oob_err)
print(hyper_grid[opt_i,])

```

```{r}
#OK, lets try that then
  
 model = gbm(formula = Richness~.,
              data = subset_mean,
              n.minobsinnode = 2,
              bag.fraction = 0.8 ,
              interaction.depth =6,
               n.trees = 10000,
               distribution = "gaussian",
               cv.folds =5)
print( model$train.error[length(model$train.error)])  


```

```{r}
pred <- predict(model,subset_mean,10000)
rmse(actual = subset_mean$Richness,
     predicted = pred)
```

```{r}
summary(model,n.trees=10000)

```

```{r}
#now need a train and test set  MEANS START HERE

#set.seed(5)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.7,0.3), replace = TRUE)

train <- subset_mean[assignment == 1, ]   
test <- subset_mean[assignment == 2, ]  

```


```{r}
nodes  = seq(2,10,1)
idepth = seq(2,6,1)
bag = seq(0.5,0.8,0.1)
hyper_grid = expand.grid(nodes = nodes, bag = bag, idepth = idepth)

oob_err = c()

for (i in 1:nrow(hyper_grid)){
 # browser()
  set.seed(1)
 model = gbm(formula = Richness~.,
              data = train,
              n.minobsinnode = hyper_grid$nodes[i],
              bag.fraction = hyper_grid$bag[i] ,
              interaction.depth =hyper_grid$idepth[i[]],
               n.trees = 10000,
               distribution = "gaussian",
               cv.folds =5)

oob_err[i] = model$train.error[length(model$train.error)]
  
 }

opt_i = which.min(oob_err)
print(hyper_grid[opt_i,])

```
Same hyper parameters on train set as when no train set used

```{r}
#run model on train set
model = gbm(formula = Richness~.,
              data = train,
              n.minobsinnode = 2,
              bag.fraction = 0.8 ,
              interaction.depth = 6,
               n.trees = 10000,
               distribution = "gaussian",
               cv.folds =5)
#print( model$train.error[length(model$train.error)])  
ntree_opt_oob = gbm.perf(model, method = "cv",oobag.curve = TRUE)

pred_test <- predict(model,test,ntree_opt_oob)
pred_train = predict(model,train,ntree_opt_oob) 

rmse_test = rmse(actual = test$Richness,   predicted = pred_test)
rmse_train = rmse(actual = train$Richness, predicted = pred_train)


rmse_test
rmse_train
```

```{r}
s = summary(model,n.trees=10000)

x = as.character(s$var)
y = s$rel.inf
data = as.data.frame(cbind(x,y))
data$y = as.numeric(levels(data$y))[data$y]
data$x <- factor(data$x, levels = data$x[order(data$y)])

ggplot(data =data , aes(x = x, y = y)) +  geom_bar(stat = "identity")+
  ylab("relative influence")+
  xlab("")+
  theme(axis.text.x=element_text(angle = 45, hjust = 1))
```

```{r}
#sd set
#now need a train and test set

set.seed(5)
assignment <- sample(1:2, size = nrow(subset_sd), prob = c(0.75,0.25), replace = TRUE)

train <- subset_sd[assignment == 1, ]   
test <- subset_sd[assignment == 2, ]  

```


```{r}
nodes  = seq(2,10,1)
idepth = seq(2,6,1)
bag = seq(0.5,0.8,0.1)
hyper_grid = expand.grid(nodes = nodes, bag = bag, idepth = idepth)

oob_err = c()

for (i in 1:nrow(hyper_grid)){
 # browser()
  set.seed(1)
 model = gbm(formula = Richness~.,
              data = train,
              n.minobsinnode = hyper_grid$nodes[i],
              bag.fraction = hyper_grid$bag[i] ,
              interaction.depth =hyper_grid$idepth[i[]],
               n.trees = 10000,
               distribution = "gaussian",
               cv.folds =5)

oob_err[i] = model$train.error[length(model$train.error)]
  
 }

opt_i = which.min(oob_err)
print(hyper_grid[opt_i,])

```
Same hyper parameters on train set as when no train set used
Gives nodes = 2, bag = 0.8, depth = 6
```{r}
#run model on test set
model = gbm(formula = Richness~.,
              data = test,
              n.minobsinnode = 3 ,
              bag.fraction = 0.85 ,
              interaction.depth =5,
               n.trees = 10000,
               distribution = "gaussian",
               cv.folds =5)
#print( model$train.error[length(model$train.error)])  


pred_test <- predict(model,test,10000)
pred_train = predict(model,train,10000) 
rmse_test = rmse(actual = test$Richness,   predicted = pred_test)
rmse_train = rmse(actual = train$Richness, predicted = pred_train)

rmse_test
rmse_train
```

```{r}
s = summary(model,n.trees=10000)

x = as.character(s$var)
y = s$rel.inf
data = as.data.frame(cbind(x,y))
data$y = as.numeric(levels(data$y))[data$y]
data$x <- factor(data$x, levels = data$x[order(data$y)])
ggplot(data =data , aes(x = x, y = y)) +  geom_bar(stat = "identity")+
  ylab("relative influence")+
  xlab("")+
  theme(axis.text.x=element_text(angle = 45, hjust = 1))

``` 

```{r}

predicted_richness = pred
empirical_richness =  test$Richness

fit = lm(empirical_richness ~ pred)
R2 = round(summary(fit)$r.squared,2)
f = summary(fit)$fstatistic
p = round(pf(f[1],f[2],f[3], lower.tail = F),4)
rmse = round(rmse(actual = empirical_richness, predicted =  predicted_richness),2)
subtitle = paste("R2 = ",R2, "p = ",p, "rmse = ", rmse)
data = as.data.frame(cbind(predicted_richness, empirical_richness))

ggplot(data, aes(x = predicted_richness, y = empirical_richness))+
  geom_point()+
  geom_abline(intercept = 0, slope = 1)+
  labs(title = "Observed versus predicted data, SD dataset",
       subtitle = subtitle)

```

