x = predt[,i]
l = length(y)
x = x[1:l]
newmod_r2[i] = summary(lm(y~x))$r.squared
}
###boxplots of R2
data1 = as.data.frame(cbind(exp_R2,pwr_R2))
data3 = as.data.frame(newmod_r2)
ggplot(data = stack(data1), aes(x = ind, y = values))+
geom_boxplot(width = 0.3, fill = "grey")+
geom_boxplot(data = data3, aes(x = "",y = newmod_r2),width = 0.3, fill = "grey")+
scale_x_discrete(labels=xticklabs)+
ggtitle("R2 values for the three models")+
ylab("R2")+
xlab("Model")
min(newmod_r2)
source('C:/dev/code/CMEECourseWork/CMEEMainProject/Code/SAC2.R')
View(ave_data)
site_88 = ave_data%>%filter(Site == 88)
View(site_88)
ggplot(site88, aes(x = areas, y = ave_cf))+geom_point()
ggplot(site_88, aes(x = areas, y = ave_cf))+geom_point()
site_20 = ave_data%>%filter(Site == 20)
ggplot(site_20, aes(x = areas, y = ave_cf))+geom_point()
a = readRDS("a.RDS")
b =  readRDS("b.RDS")
c = readRDS("c.RDS")
new_mod_zetas = readRDS("new_model_zetas")
new_mod_coefs = readRDS("new_mod_coefs")
areas = CompleteSiteLevelvars%>%select(Site,Area_ha,Richness)
CompleteSiteLevelvars = read.csv("../../Data/CompleteSiteLevelVars.csv")
a = readRDS("a.RDS")
b =  readRDS("b.RDS")
c = readRDS("c.RDS")
new_mod_zetas = readRDS("new_model_zetas")
new_mod_coefs = readRDS("new_mod_coefs")
areas = CompleteSiteLevelvars%>%select(Site,Area_ha,Richness)
rownames(areas) = areas$Site
areas_sorted = areas[order(areas$Site),]
subset_woods = areas_sorted[-(sites_to_remove),]
sites_to_remove = c(5,8,24,44,62,64,67,94)
a = readRDS("a.RDS")
b =  readRDS("b.RDS")
c = readRDS("c.RDS")
new_mod_zetas = readRDS("new_model_zetas")
new_mod_coefs = readRDS("new_mod_coefs")
areas = CompleteSiteLevelvars%>%select(Site,Area_ha,Richness)
rownames(areas) = areas$Site
areas_sorted = areas[order(areas$Site),]
subset_woods = areas_sorted[-(sites_to_remove),]
subset_woods$orders = (subset_woods$Area_ha)*5 # areas in ha, so areax10000/200 = areax5
#first just calc richness to order = 16
#get the databases in the right order
subset_woods$mod_rich = mod_rich
View(subset_woods)
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE
)
rm(list = ls())
cat("\014")
library(dplyr)
library(rpart)
library(rpart.plot)
library(gbm)#bgm
library(caret)
library(Metrics) #rmse
library(randomForest)
site_data =  read.csv("../../Data/CompleteSiteLevelVars.csv")
site_data = site_data[,-1]
#mean impute the missing PHI
meanPHI = round(mean(site_data$Pos_Hetero_Index, na.rm = TRUE),2)
x = site_data$Pos_Hetero_Index
x[is.na(x)] = meanPHI
site_data$Pos_Hetero_Index = x
subset_all = site_data%>%select("Site","Richness","Area_ha",
"Northing", "Pos_Hetero_Index","Buffer3",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_treedensity","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meantreedensity")
colnames(subset_all) = c("Site","Richness","Area",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio",
"meandbh","meanph", "meanSOM","meanLBA",
"meanTD")
subset_sd = subset_all%>%select("Richness",
"Northing", "PHI","Buffer",
"no_MSG", "no_NVC","sd_pH","sd_SOM","sd_LBA",
"sd_meandbh","sd_TD","area_ratio")
subset_mean = subset_all%>%select("Richness",
"Northing", "PHI",  "meandbh",
"meanph", "Buffer", "meanSOM","meanLBA",
"meanTD","area_ratio", "no_NVC",
"no_MSG")
# make train and test sets
set.seed(1)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to validation indices only
#tuning
mtry = seq(2,11,1)
nodesize = seq(2,10,2)
sampsize = nrow(train)*c(0.7,0.8)
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
oob_err = c()
for (i in 1:nrow(hyper_grid)){
# browser()
model = randomForest(formula = Richness~.,
data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i] ,
sampsize = hyper_grid$sampsize[i] )
oob_err[i] = model$mse[length(model$mse)]
}
opt_i = which.min(oob_err)
print(hyper_grid[opt_i,])
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
varImpPlot(forest)
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
#tuning
mtry = seq(2,11,1)
nodesize = seq(2,10,2)
sampsize = nrow(train)*c(0.7,0.8)
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
oob_err = c()
for (i in 1:nrow(hyper_grid)){
# browser()
model = randomForest(formula = Richness~.,
data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i] ,
sampsize = hyper_grid$sampsize[i] )
oob_err[i] = model$mse[length(model$mse)]
}
opt_i = which.min(oob_err)
print(hyper_grid[opt_i,])
#tuning
mtry = seq(2,11,1)
nodesize = seq(2,10,2)
sampsize = nrow(train)*c(0.7,0.8)
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
oob_err = c()
for (i in 1:nrow(hyper_grid)){
# browser()
model = randomForest(formula = Richness~.,
data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i] ,
sampsize = hyper_grid$sampsize[i] )
oob_err[i] = model$mse[length(model$mse)]
}
opt_i = which.min(oob_err)
print(hyper_grid[opt_i,])
#tuning
mtry = seq(2,11,1)
nodesize = seq(2,10,2)
sampsize = nrow(train)*c(0.7,0.8)
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
oob_err = c()
for (i in 1:nrow(hyper_grid)){
# browser()
model = randomForest(formula = Richness~.,
data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i] ,
sampsize = hyper_grid$sampsize[i] )
oob_err[i] = model$mse[length(model$mse)]
}
opt_i = which.min(oob_err)
print(hyper_grid[opt_i,])
#tuning
mtry = seq(2,11,1)
nodesize = seq(2,10,2)
sampsize = nrow(train)*c(0.7,0.8)
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
oob_err = c()
for (i in 1:nrow(hyper_grid)){
# browser()
model = randomForest(formula = Richness~.,
data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i] ,
sampsize = hyper_grid$sampsize[i] )
oob_err[i] = model$mse[length(model$mse)]
}
opt_i = which.min(oob_err)
print(hyper_grid[opt_i,])
#tuning
mtry = seq(2,11,1)
nodesize = seq(2,10,2)
sampsize = nrow(train)*c(0.7,0.8)
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
oob_err = c()
for (i in 1:nrow(hyper_grid)){
# browser()
model = randomForest(formula = Richness~.,
data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i] ,
sampsize = hyper_grid$sampsize[i] )
oob_err[i] = model$mse[length(model$mse)]
}
opt_i = which.min(oob_err)
print(hyper_grid[opt_i,])
#tuning
mtry = seq(2,11,1)
nodesize = seq(2,10,2)
sampsize = nrow(train)*c(0.7,0.8)
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
oob_err = c()
for (i in 1:nrow(hyper_grid)){
# browser()
model = randomForest(formula = Richness~.,
data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i] ,
sampsize = hyper_grid$sampsize[i] )
oob_err[i] = model$mse[length(model$mse)]
}
opt_i = which.min(oob_err)
print(hyper_grid[opt_i,])
#tuning
mtry = seq(2,11,1)
nodesize = seq(2,10,2)
sampsize = nrow(train)*c(0.7,0.8)
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
oob_err = c()
for (i in 1:nrow(hyper_grid)){
# browser()
model = randomForest(formula = Richness~.,
data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i] ,
sampsize = hyper_grid$sampsize[i] )
oob_err[i] = model$mse[length(model$mse)]
}
opt_i = which.min(oob_err)
print(hyper_grid[opt_i,])
#tuning
mtry = seq(2,11,1)
nodesize = seq(2,10,2)
sampsize = nrow(train)*c(0.7,0.8)
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
oob_err = c()
for (i in 1:nrow(hyper_grid)){
# browser()
model = randomForest(formula = Richness~.,
data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i] ,
sampsize = hyper_grid$sampsize[i] )
oob_err[i] = model$mse[length(model$mse)]
}
opt_i = which.min(oob_err)
print(hyper_grid[opt_i,])
#tuning
mtry = seq(2,11,1)
nodesize = seq(2,10,2)
sampsize = nrow(train)*c(0.7,0.8)
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
oob_err = c()
for (i in 1:nrow(hyper_grid)){
# browser()
model = randomForest(formula = Richness~.,
data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i] ,
sampsize = hyper_grid$sampsize[i] )
oob_err[i] = model$mse[length(model$mse)]
}
opt_i = which.min(oob_err)
print(hyper_grid[opt_i,])
#tuning
mtry = seq(2,11,1)
nodesize = seq(2,10,2)
sampsize = nrow(train)*c(0.7,0.8)
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
oob_err = c()
for (i in 1:nrow(hyper_grid)){
# browser()
model = randomForest(formula = Richness~.,
data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i] ,
sampsize = hyper_grid$sampsize[i] )
oob_err[i] = model$mse[length(model$mse)]
}
opt_i = which.min(oob_err)
print(hyper_grid[opt_i,])
#tuning
mtry = seq(2,11,1)
nodesize = seq(2,10,2)
sampsize = nrow(train)*c(0.7,0.8)
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
oob_err = c()
for (i in 1:nrow(hyper_grid)){
# browser()
model = randomForest(formula = Richness~.,
data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i] ,
sampsize = hyper_grid$sampsize[i] )
oob_err[i] = model$mse[length(model$mse)]
}
opt_i = which.min(oob_err)
print(hyper_grid[opt_i,])
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 6,
nodesize = 2,
sampsize = 53)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
#removing noMSG and area ratio as these keep coming up as negative MSE
#removing northing as we have decided that northing and buffer are the same
subset_mean = subset_all%>%select("Richness",
"PHI",  "meandbh",
"meanph", "Buffer" ,"meanSOM","meanLBA",
"meanTD", "no_NVC")
# make train and test sets
set.seed(1)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to validation indices only
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 8,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 8,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 8,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 8,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
# make train and test sets
set.seed(1)
assignment <- sample(1:2, size = nrow(subset_mean), prob = c(0.75,0.25), replace = TRUE)
# Create a train, validation and tests from the original data frame
train <- subset_mean[assignment == 1, ]    # subset the grade data frame to training indices only
test <- subset_mean[assignment == 2, ]  # subset the grade data frame to validation indices only
mtry = seq(2,11,1)
nodesize = seq(2,10,2)
sampsize = nrow(train)*c(0.7,0.8)
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
oob_err = c()
for (i in 1:nrow(hyper_grid)){
# browser()
model = randomForest(formula = Richness~.,
data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i] ,
sampsize = hyper_grid$sampsize[i] )
oob_err[i] = model$mse[length(model$mse)]
}
opt_i = which.min(oob_err)
print(hyper_grid[opt_i,])
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 10,
nodesize = 2,
sampsize = 53)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 10,
nodesize = 2,
sampsize = 53)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
mtry = seq(2,11,1)
nodesize = seq(2,10,2)
sampsize = nrow(train)*c(0.7,0.8)
hyper_grid = expand.grid(mtry = mtry, nodesize = nodesize, sampsize = sampsize)
oob_err = c()
for (i in 1:nrow(hyper_grid)){
# browser()
model = randomForest(formula = Richness~.,
data = train,
mtry = hyper_grid$mtry[i],
nodesize = hyper_grid$nodesize[i] ,
sampsize = hyper_grid$sampsize[i] )
oob_err[i] = model$mse[length(model$mse)]
}
opt_i = which.min(oob_err)
print(hyper_grid[opt_i,])
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 12,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
varImp(forest)
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 2,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImp(forest)
vi = varImp(forest)
vi[1]
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 4,
nodesize = 8,
sampsize = 61)
pred= predict(object = forest, newdata = test)
rmse(actual = test$Richness,
predicted = pred)
varImpPlot(forest)
varimp = data.frame()
for (i in 1:100){
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 4,
nodesize = 8,
sampsize = 61)
vi = varImp(forest)
varimp = cbind(varimp,vi)
}
varimp = data.frame(nrow = 8)
for (i in 1:100){
forest = randomForest(formula = Richness~., data = train,importance = TRUE,
mtry = 4,
nodesize = 8,
sampsize = 61)
vi = varImp(forest)
varimp = cbind(varimp,vi)
}
varimp
