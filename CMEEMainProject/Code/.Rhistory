Data_Yr2_veg%>%filter(Site == 96)%>% (PLOT == 4)
knitr::opts_chunk$set(echo = FALSE,message = FALSE,fig.pos = "H" ,comment=NA, fig.align ="centre")
date = format(Sys.Date(), "%B %d %Y")
cat(date)
#clear the workspace
rm(list = ls())
cat("\014")
#setwd("~/Documents/CMEECourseWork/MiniProject/Code")
library(ggplot2)
library(reshape) # both required for the box plots, otherwise they cant all be presented
# on one page and therefore difficult to analyse
library(rpart)
library(rpart.plot)# both required for the decision tree
library(knitr)
library(kableExtra) # for kable stylig options, to hold position on page
#Get the data , enter input CSV file name here, for data in data directory
inputfile = 'SorariaCompact1.csv'
Dataname = strsplit(inputfile, "\\.")[[1]][[1]]
fullfile = paste("../Data",inputfile,sep = '/')
Data = read.csv(fullfile)
speciesnames = as.character(unique(unlist(Data$Species))) # uselful for nameing things
numspecies = summary(Data$Species) # useful for comparisons
#Median imputation
median_replace1 = function(x){
ifelse(is.na(x), median(x,na.rm = TRUE), x)
}
median_replace2 = function(x){
apply(x,2,median_replace1)
}
Imputed_list = lapply(split.data.frame(Data[,2:12], Data$Species), FUN = median_replace2)
# Some algorthms are sensitive to the scale of the data, so here the entire dataframe is scaled
Scaled_df = scale(Imputed_df[-1])
#The imputed dataframe is a list with species as the elements, the following sticks it back together with a different name so both optiona are available
temp = do.call(rbind, Imputed_list)
Imputed_df = cbind(Data[1], temp)
# Some algorthms are sensitive to the scale of the data, so here the entire dataframe is scaled
Scaled_df = scale(Imputed_df[-1])
Scaled_df = cbind(Data[1], Scaled_df)
# but this might reduce the dissimilarity to much, so this is a semi-scaled datafrane.
temp = Imputed_df[-c(1,6,7,8,12)]
temp = scale(temp)
Semi_Scaled_df = cbind(Imputed_df[c(1,6:8,12)], temp)
# Model evaluation metrics
accuracy = function(atable){
a = round(sum(diag(atable)/sum(atable)), digits = 2)
return(a)
}
# precision = TP/( rest of that column in conf matrix = the other species id in same class)
precision = function(atable){
p = vector()
items = vector()
no_predictions = dim(atable)[2]
for (i in 1:no_predictions){
items[i] = paste("class",colnames(atable)[i], sep = "_")
p[i] = round(diag(atable)[i]/(sum((atable)[,i])), digits = 2)
}
precisions = cbind(items,p)
colnames(precisions) = c("Class", "Precision")
return(precisions)
}
#sensitivity = TP/ rest of that row = the other classes the algorithm has put species in
sensitivity = function(atable){
s = vector()
no_actuals = dim(atable)[1]
for (i in 1:no_actuals){
s[i] = round(diag(atable)[i]/(sum((atable)[i,])), digits = 2)
}
sensitivities = cbind(rownames(atable),s)
colnames(sensitivities) = c("Species", "Sensitivity")
return(sensitivities)
}
#Data sampling and test/train sets.
#This shuffles and splits the data
shuffle = function(dataset){
splits = list()
set.seed(42)
n = nrow(dataset)
shuffled = dataset[sample(n),]
train = shuffled[1:round(0.7*n),]
test = shuffled[(round(0.7*n)+1):n,]
splits[[1]] = train
splits[[2]] = test
return(splits)
}
#this subsets the data into species
create_train_test = function(dataset){
sets = as.character(unique(dataset[,1]))
train = data.frame()
test = data.frame()
split_data = list()
for (i in 1:length(sets)){
sub = subset(dataset, dataset[,1] == sets[i])
train_temp = shuffle(sub)[[1]]
test_temp = shuffle(sub)[[2]]
train = rbind(train, train_temp)
test = rbind(test, test_temp)
}
split_data[[1]] = train
split_data[[2]] = test
return(split_data)
}
#PS you can check the splits are correct with summary(train$species), summary(test$species)
#summary(maindata$species), this gives numbers in each species.
#to include a cross fold validation repeat above fold times
# performs the k means algorith over 10 repeats, returns BSS/Wss ratio, accuracy and
repeated_kmeans = function(dataset){
metrics_list = list()
accuracy_vector = vector()
ratio = vector()
species_no = data.frame(matrix(ncol = 7))
colnames(species_no) = speciesnames
sens = data.frame(row.names = speciesnames )
prec = data.frame(rownames = speciesnames)
for (i in 1:10){
kmeans_result = kmeans(dataset[-1], 7, 20, iter.max = 50, algorithm = "MacQueen")
ratio[i] = round(kmeans_result$tot.withinss/kmeans_result$totss, digits = 2)
kmeans_conf = table(Imputed_df$Species, kmeans_result$cluster)
accuracy_vector[i] = accuracy(kmeans_conf)
species = diag(kmeans_conf)
species_no = rbind(species_no, species)# just TP
s = sensitivity(kmeans_conf)
sens = cbind(sens, s[,2])
p = precision(kmeans_conf)
prec = cbind(prec,p[,2])
}
metrics_list[[1]] = ratio # wss/bss
metrics_list[[2]] = accuracy_vector #sum TP/no things done
metrics_list[[3]] = species_no[-1,]
metrics_list[[4]] = sens
metrics_list[[5]] = prec
return(metrics_list)
}
#Getting the results for the kmeans
#Imputed df without scaling
Imputed_kmeans = repeated_kmeans(Imputed_df)
#Semi scaled data
#Semi_scaled_kmeans = repeated_kmeans(Semi_Scaled_df)
# fully scaled data
Scaled_kmeans = repeated_kmeans(Scaled_df)
#Display accuaracy for kmeans calcualted above.
acc_df = data.frame(nrow = 2)
acc_df = rbind(Imputed_kmeans[[2]],Scaled_kmeans[[2]])
rownames(acc_df) = c("unstandardized","standardized")
colnames(acc_df) = c("Run 1","Run 2","Run 3","Run 4","Run 5","Run 6","Run 7", "Run 8","Run 9","Run 10")
kable(acc_df, format = "latex", caption = "Accuracy")%>%
kable_styling(latex_options = "hold_position")
#Display accuaracy for kmeans calcualted above.
acc_df = data.frame(nrow = 2)
acc_df = rbind(Imputed_kmeans[[2]],Scaled_kmeans[[2]])
rownames(acc_df) = c("non-standardized","standardized")
colnames(acc_df) = c("Run 1","Run 2","Run 3","Run 4","Run 5","Run 6","Run 7", "Run 8","Run 9","Run 10")
kable(acc_df, format = "latex", caption = "Accuracy")%>%
kable_styling(latex_options = "hold_position")
#Display percentage of true positives from the confusion matrix calcualted in kmeans chunk above
m1 = Imputed_kmeans[[3]]
#m2 = Semi_scaled_kmeans[[3]]
m3 = Scaled_kmeans[[3]]
m1_percent = round(apply(m1, 1, function(x) (x/numspecies)*100), digits = 2)
colnames(m1_percent) = c(1:10)
kable(m1_percent, format = "latex", caption = "Percentage of true positives for non-standarized data")%>%
kable_styling(latex_options = "hold_position")
m2_percent = round(apply(m2, 1, function(x) (x/numspecies)*100), digits = 2)
m3_percent = round(apply(m3, 1, function(x) (x/numspecies)*100), digits = 2)
colnames(m3_percent) = c(1:10)
kable(m3_percent, format = "latex", caption = "Percentage of true positives for standarized data")%>%
kable_styling(latex_options = "hold_position")
prec_df_Imputed = Imputed_kmeans[[4]]
colnames(prec_df_Imputed) = c(1:10)
kable(prec_df_Imputed, format = "latex", caption = "Precision of kmeans with non standardized data")%>%
kable_styling(latex_options = "hold_position")
prec_df = Scaled_kmeans[[4]]
colnames(prec_df) = c(1:10)
kable(prec_df, format = "latex", caption = "Precision of kmeans with standardized data")%>%
kable_styling(latex_options = "hold_position")
sens_df_Imputed = Imputed_kmeans[[4]]
colnames(sens_df_Imputed) = c(1:10)
kable(sens_df_Imputed, format = "latex", caption = "Sensitivity of kmeans with non standardized data")%>%
kable_styling(latex_options = "hold_position")
knitr::opts_chunk$set(echo = FALSE,message = FALSE,fig.pos = "H" ,comment=NA, fig.align ="centre")
#clear the workspace
rm(list = ls())
cat("\014")
#setwd("~/Documents/CMEECourseWork/MiniProject/Code")
library(ggplot2)
library(reshape) # both required for the box plots, otherwise they cant all be presented
# on one page and therefore difficult to analyse
library(rpart)
library(rpart.plot)# both required for the decision tree
library(knitr)
library(kableExtra) # for kable stylig options, to hold position on page
library(rmarkdown)
knitr::opts_chunk$set(echo = FALSE)
rm(list = ls())
cat("\014")
library(dplyr)
library(ggplot2)
library(ggmap)
library(ggrepel)
library(nlme)
library(reshape)
library(gridExtra)
setwd("~/Documents/CMEECourseWork/CMEEMainProject/Code")
#the wood location data
woods = read.csv("../Data/EastingNorthing.csv")
colnames(woods) = c("Site", "Easting","Northing","GridRef","Lat","Long")
#just for plotting
data = cbind(woods$Lat, woods$Long)
#Input all the ground flora data
Data = read.csv("../Data/GroundCover.csv")
Data_Yr2 = Data%>%filter(Yr_2 == 2)#%>%select(SITE,PLOT,NEST,COV,Amalgams)
colnames(Data_Yr2) = c("SITE", "PLOT","NEST","Cover","BRC_number","Year")
veg_codes = read.csv("../Data/vegetation_codes.csv")
# the  bryophytes, lichen etc have already been removed from these, so the veg codes csv files is no bryophytes, so need to join this with ground cover to eliminate bryophytes from counts
colnames(veg_codes) = c("Species", "BRC_number")
Data_Yr2_veg = Data_Yr2%>% inner_join(veg_codes)
# now using Dat_Yr2_veg means analysis is carried out without bryophytes
# returns the species richness for each site/plot/nest
# NAs are not counted, these occur for sapling counts which need to be added in to the plot richness.
nest_richness = function(data){
site_list = list()
#browser()
for (i in 1:103){
sitedata = data%>%filter(SITE == i)
plot_nest_df = data.frame()
for (j in 1:16){
plotdata = sitedata%>%filter(PLOT == j)
tmp = vector()
for (k in 1:5){
nestdata = plotdata%>%filter(NEST ==k)
tmp = c(tmp, nrow(nestdata))
}
plot_nest_df = rbind(plot_nest_df, tmp)
colnames(plot_nest_df) = c("nest1","nest2","nest3","nest4","nest5")
}
site_list[[i]]= plot_nest_df
}
return(site_list)
}
spec_rich = nest_richness(Data_Yr2_veg)
# now need to include the NAs and combine them into a plot richness
plot_richness = function(data){
site_matrix = matrix(nrow = 103, ncol = 16)
#browser()
for (i in 1:103){
sitedata = data%>%filter(SITE == i)
plot_nest_df = data.frame()
for (j in 1:16){
plotdata = sitedata%>%filter(PLOT == j)
site_matrix[i,j] = length(unique(plotdata$BRC_number))
}
}
return(site_matrix)
}
plot_rich = plot_richness(Data_Yr2_veg)
write.csv(plot_rich,"../Data/plot_rich.csv")
# just calculates richness found in each wood, no extrapolation.
#d[i] is richness of wood i
basic_richness = function(data){
d = rep(0,103)
for (i in 1:103){
site = data%>%filter(SITE==i)
d[i]  = length(unique(site$BRC_number))
}
return(d)
}
d = basic_richness(Data_Yr2_veg)
## cumulative richness for site 1, for all 16 plots.
##need spec_rich calculated above
cum_rich_all = list()
for ( i in 1:103){
#browser()
site = spec_rich[[i]]
site = as.data.frame(site)
cum_rich_site = data.frame()
for (j in 1:16) {
plot = site[j,]
r = 0
cumrich = rep(0,5)
for (n in 1:5){
r = r + plot[[n]]
cumrich[n] = r
}
cum_rich_site = rbind(cum_rich_site, cumrich)
}
colnames(cum_rich_site) = c("nest1","nest2","nest3","nest4","nest5")
cum_rich_all[[i]] = cum_rich_site
}
View(cum_rich_site)
View(cum_rich_all)
View(spec_rich)
View(plot_rich)
View(plot_rich)
View(plot_rich)
View(spec_rich)
cum_rich_all[[2]]
?par
par(mfrow =c(3,2), mai = c(0,0,0,0))
plot(x = x1, y = y, main = "by NVC")
plot(x = x2, y = y, main = "by pH")
plot(x = x3, y = y, main = "by SOM")
plot(x = x4, y = y, main = "by LBA")
plot(x=x5, y=y, main = "by mean DBH")
plot(x = x6, y = y, main = "by tree density")
dev.off()
par(mfrow =c(3,2), mai = c(0,0,0,0))
plot(x = x1, y = y, main = "by NVC")
plot(x = x2, y = y, main = "by pH")
plot(x = x3, y = y, main = "by SOM")
plot(x = x4, y = y, main = "by LBA")
plot(x=x5, y=y, main = "by mean DBH")
plot(x = x6, y = y, main = "by tree density")
dev.off()
par(mfrow =c(3,2), mai = c(0,0,0,0))
plot(x = x1, y = y, main = "by NVC")
plot(x = x2, y = y, main = "by pH")
plot(x = x3, y = y, main = "by SOM")
plot(x = x4, y = y, main = "by LBA")
plot(x=x5, y=y, main = "by mean DBH")
plot(x = x6, y = y, main = "by tree density")
y = all_plot_vars$plot_richness
x1 = as.factor(all_plot_vars$ShortNVC)
x2= as.factor(round(all_plot_vars$pHYr2, digits = 0))
x3 = as.factor(round(all_plot_vars$SOMYr2, digits = 0))
x4 = as.factor(round(all_plot_vars$LiveBasalAreaYr2, digits = 0))
x5 =  as.factor(round(all_plot_vars$mean_dbh, digits = 0))
x6 =  as.factor(round(all_plot_vars$`tree density`, digits = 1))
Data = read.csv("../Data/GroundCover.csv")
Data_Yr2 = Data%>%filter(Yr_2 == 2)#%>%select(SITE,PLOT,NEST,COV,Amalgams)
colnames(Data_Yr2) = c("SITE", "PLOT","NEST","Cover","BRC_number","Year")
veg_codes = read.csv("../Data/vegetation_codes.csv")
colnames(veg_codes) = c("Species", "BRC_number")
Data_Yr2_veg = Data_Yr2%>% inner_join(veg_codes)
# now using Dat_Yr2_veg means analysis is carried out without bryophytes
data_plots = read.csv("../Data/AnalysisEnvDataLevelPlot.csv") # this provides pH, livebasal area, SOM
#means come from MainProjDBH
data_dbh = read.csv("../Data/dbh_means.csv")
#tree_density calcuated in MainProjDBH, is sum of all trees over all dbh classes/200m2
#BUT - saplings only counted in 2 quadrants
data_tree_density = read.csv("../Data/tree_density.csv")
#plot_richness come from ExploringNests
data_rich = read.csv("../Data/plot_rich.csv")
#wrangle
# get data into long format of columns Site (with 16 plots), pH, SOM, etc
tmp_plot_vars = data_plots[c(1,2,5,7,9,11,12,14)]
data_dbh_long = data.frame()
Plot = c(1:16)
for (i in 1:103){
r = as.vector(t(data_dbh[i, c(2:17)]))
Site = rep(i,16)
tmp = as.data.frame(cbind(Site,Plot,r))
colnames(tmp) = c("Site","Plot","mean_dbh")
data_dbh_long = rbind(data_dbh_long,tmp)
}
data_density_long = data.frame()
Plot = c(1:16)
for (i in 1:103){
r = as.vector(t(data_tree_density[i, c(2:17)]))
Site = rep(i,16)
tmp = as.data.frame(cbind(Site,Plot,r))
colnames(tmp) = c("Site","Plot","tree density")
data_density_long = rbind(data_density_long,tmp)
}
data_rich_long = data.frame()
Plot = c(1:16)
for (i in 1:103){
r = as.vector(t(data_rich[i, c(2:17)]))
Site = rep(i,16)
tmp = as.data.frame(cbind(Site,Plot,r))
colnames(tmp) = c("Site","Plot","plot_richness")
data_rich_long = rbind(data_rich_long,tmp)
}
#join tmp plot vars with data dbh long, data density long and data rich long
tmp_all = inner_join(tmp_plot_vars,data_dbh_long)
tmp_all = inner_join(tmp_all, data_density_long)
all_plot_vars = inner_join(tmp_all, data_rich_long)
all_plot_vars$ShortNVC = gsub("[[:lower:]]","",all_plot_vars$Yr2NVC)
setwd("~/Documents/CMEECourseWork/CMEEMainProject/Code")
Data = read.csv("../Data/GroundCover.csv")
Data_Yr2 = Data%>%filter(Yr_2 == 2)#%>%select(SITE,PLOT,NEST,COV,Amalgams)
colnames(Data_Yr2) = c("SITE", "PLOT","NEST","Cover","BRC_number","Year")
veg_codes = read.csv("../Data/vegetation_codes.csv")
colnames(veg_codes) = c("Species", "BRC_number")
Data_Yr2_veg = Data_Yr2%>% inner_join(veg_codes)
# now using Dat_Yr2_veg means analysis is carried out without bryophytes
data_plots = read.csv("../Data/AnalysisEnvDataLevelPlot.csv") # this provides pH, livebasal area, SOM
#means come from MainProjDBH
data_dbh = read.csv("../Data/dbh_means.csv")
#tree_density calcuated in MainProjDBH, is sum of all trees over all dbh classes/200m2
#BUT - saplings only counted in 2 quadrants
data_tree_density = read.csv("../Data/tree_density.csv")
#plot_richness come from ExploringNests
data_rich = read.csv("../Data/plot_rich.csv")
#wrangle
# get data into long format of columns Site (with 16 plots), pH, SOM, etc
tmp_plot_vars = data_plots[c(1,2,5,7,9,11,12,14)]
data_dbh_long = data.frame()
Plot = c(1:16)
for (i in 1:103){
r = as.vector(t(data_dbh[i, c(2:17)]))
Site = rep(i,16)
tmp = as.data.frame(cbind(Site,Plot,r))
colnames(tmp) = c("Site","Plot","mean_dbh")
data_dbh_long = rbind(data_dbh_long,tmp)
}
data_density_long = data.frame()
Plot = c(1:16)
for (i in 1:103){
r = as.vector(t(data_tree_density[i, c(2:17)]))
Site = rep(i,16)
tmp = as.data.frame(cbind(Site,Plot,r))
colnames(tmp) = c("Site","Plot","tree density")
data_density_long = rbind(data_density_long,tmp)
}
data_rich_long = data.frame()
Plot = c(1:16)
for (i in 1:103){
r = as.vector(t(data_rich[i, c(2:17)]))
Site = rep(i,16)
tmp = as.data.frame(cbind(Site,Plot,r))
colnames(tmp) = c("Site","Plot","plot_richness")
data_rich_long = rbind(data_rich_long,tmp)
}
#join tmp plot vars with data dbh long, data density long and data rich long
tmp_all = inner_join(tmp_plot_vars,data_dbh_long)
tmp_all = inner_join(tmp_all, data_density_long)
all_plot_vars = inner_join(tmp_all, data_rich_long)
all_plot_vars$ShortNVC = gsub("[[:lower:]]","",all_plot_vars$Yr2NVC)
#plot of all NVC codes and richnesses across all woods, so spread is due to wood.
y = all_plot_vars$plot_richness
x1 = as.factor(all_plot_vars$ShortNVC)
x2= as.factor(round(all_plot_vars$pHYr2, digits = 0))
x3 = as.factor(round(all_plot_vars$SOMYr2, digits = 0))
x4 = as.factor(round(all_plot_vars$LiveBasalAreaYr2, digits = 0))
x5 =  as.factor(round(all_plot_vars$mean_dbh, digits = 0))
x6 =  as.factor(round(all_plot_vars$`tree density`, digits = 1))
par(mfrow =c(3,2), mai = c(0,0,0,0))
plot(x = x1, y = y, main = "by NVC")
plot(x = x2, y = y, main = "by pH")
plot(x = x3, y = y, main = "by SOM")
plot(x = x4, y = y, main = "by LBA")
plot(x=x5, y=y, main = "by mean DBH")
plot(x = x6, y = y, main = "by tree density")
par(mfrow =c(3,2), mai = c(0.2,0.2,0.2,0.2))
plot(x = x1, y = y, main = "by NVC")
plot(x = x2, y = y, main = "by pH")
plot(x = x3, y = y, main = "by SOM")
plot(x = x4, y = y, main = "by LBA")
plot(x=x5, y=y, main = "by mean DBH")
plot(x = x6, y = y, main = "by tree density")
png("../Data/Talk/plot_vars.png")
par(mfrow =c(3,2), mai = c(0.2,0.2,0.2,0.2))
plot(x = x1, y = y, main = "by NVC")
plot(x = x2, y = y, main = "by pH")
plot(x = x3, y = y, main = "by SOM")
plot(x = x4, y = y, main = "by LBA")
plot(x=x5, y=y, main = "by mean DBH")
plot(x = x6, y = y, main = "by tree density")
dev.off()
rm(list = ls())
cat("\014")
setwd("~/Documents/CMEECourseWork/CMEEMainProject/Code")
Data = read.csv("../Data/GroundCover.csv")
Data_Yr2 = Data%>%filter(Yr_2 == 2)#%>%select(SITE,PLOT,NEST,COV,Amalgams)
colnames(Data_Yr2) = c("SITE", "PLOT","NEST","Cover","BRC_number","Year")
veg_codes = read.csv("../Data/vegetation_codes.csv")
# the  bryophytes, lichen etc have already been removed from these, so the veg codes csv files is no bryophytes, so need to join this with ground cover to eliminate bryophytes from counts
colnames(veg_codes) = c("Species", "BRC_number")
Data_Yr2_veg = Data_Yr2%>% inner_join(veg_codes)
ellenbergs = read.csv("../Data/Spp_lib.csv")
View(ellenbergs)
View(ellenbergs)
View(Data_Yr2)
View(Data_Yr2)
View(Data_Yr2_veg)
View(Data_Yr2_veg)
colnames(ellenbergs)
ellenberg  = ellenbergs[c(2,3,5,6,7,8)]
View(ellenbergs)
View(ellenbergs)
ellenbergs  = ellenbergs[c(2,3,5,6,7,8)]
colnames(ellenbergs)
colnames(ellenbergs) = c("Species","BRC_Number","R","N","W","L")
veg_ellens = inner_join(Data_Yr2_veg,ellenbergs)
View(veg_ellens)
View(veg_ellens)
colnames(ellenbergs) = c("BRC_Name","BRC_number","R","N","W","L")
veg_ellens = inner_join(Data_Yr2_veg,ellenbergs)
View(veg_ellens)
View(veg_ellens)
View(Data_Yr2_veg)
?inner_join
veg_ellens = left_join(Data_Yr2_veg,ellenbergs)
innerjoin(veg_ellens,Data_Yr2_veg)
anti_join(veg_ellens,Data_Yr2_veg)
veg_ellens = semi_join(Data_Yr2_veg,ellenbergs)
veg_ellens = innerjoin_join(Data_Yr2_veg,ellenbergs)
veg_ellens = inner_join(Data_Yr2_veg,ellenbergs)
veg_ellens = inner_join(Data_Yr2_veg,ellenbergs)
anti_join(veg_ellens,Data_Yr2_veg)
what = anti_join(Data_Yr2_veg, veg_ellens)
View(what)
View(ellenbergs)
View(ellenbergs)
View(what)
veg_ellens = right_join(Data_Yr2_veg,ellenbergs)
veg_ellens = left_join(Data_Yr2_veg,ellenbergs)
what = anti_join(veg_ellens,Data_Yr2_veg)
View(what)
what = anti_join(Data_Yr2_veg,veg_ellens)
what
what = anti_join(Data_Yr2_veg,veg_ellens)
length(unique(veg_ellens))
