---
title: "Can machine Learning be used to identify species of Sorbus"
author: "PetraGuy"
output: pdf_document
---
```{r, echo = FALSE, comment=NA}
date = format(Sys.Date(), "%B %d %Y")
cat(date)
```
#This creates pdf from command line, note, sensitive to ' or "

#Rscript -e "library(knitr); knit('MiniProj2.Rmd')"

#Rscript -e "library(rmarkdown); render('MiniProj2.md')"
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, comment=NA)
```


```{r}
#clear the workspace
rm(list = ls())
cat("\014")
setwd("~/Documents/CMEECourseWork/MiniProject/Code")

```

```{r}
#Get the data , enter input CSV file name here, for data in data directory
inputfile = 'SorariaCompact1.csv'
Dataname = strsplit(inputfile, "\\.")[[1]][[1]]
fullfile = paste("../Data",inputfile,sep = '/')
Data = read.csv(fullfile)
speciesnames = as.character(unique(unlist(Data$Species))) # uselful for nameing things
numspecies = summary(Data$Species) # useful for comparisons

```

```{r}
#Median imputation 
median_replace1 = function(x){
  ifelse(is.na(x), median(x,na.rm = TRUE), x)
 }

median_replace2 = function(x){
  apply(x,2,median_replace1)
}

Imputed_list = lapply(split.data.frame(Data[,2:12], Data$Species), FUN = median_replace2)
```

```{r}
#The imputed dataframe is a list with species as the elements, the following sticks it back together with a different name so both optiona are available
temp = do.call(rbind, Imputed_list)
Imputed_df = cbind(Data[1], temp)
```

```{r}
# Some algorthms are sensitive to the scale of the data, so here the entire dataframe is scaled
Scaled_df = scale(Imputed_df[-1])
Scaled_df = cbind(Data[1], Scaled_df)

# but this might reduce the dissimilarity to much, so this is a semi-scaled datafrane.

temp = Imputed_df[-c(1,6,7,8,12)]
temp = scale(temp)
Semi_Scaled_df = cbind(Imputed_df[c(1,6:8,12)], temp)

```

```{r}
# Model evaluation metrics

accuracy = function(atable){
  a = round(sum(diag(atable)/sum(atable)), digits = 2)
  return(a)
}

precision = function(atable){
  p = vector()
  items = vector()
  no_predictions = dim(atable)[2] 
  for (i in 1:no_predictions){
    items[i] = paste("class",colnames(atable)[i], sep = "_")
    p[i] = round(diag(atable)[i]/(sum((atable)[,i])), digits = 2)
  }
  precisions = cbind(items,p)
  colnames(precisions) = c("Class", "Precision")
  return(precisions)
}

sensitivity = function(atable){
  s = vector()
  no_actuals = dim(atable)[1] 
    for (i in 1:no_actuals){
    s[i] = round(diag(atable)[i]/(sum((atable)[i,])), digits = 2)
  }
  sensitivities = cbind(rownames(atable),s)
  return(sensitivities)
}

```


```{r}
#Data sampling and test/train sets.

#This shuffles and splits the data
shuffle = function(dataset){
  splits = list()
  set.seed(42)
  n = nrow(dataset)
  shuffled = dataset[sample(n),]
  train = shuffled[1:round(0.7*n),]
  test = shuffled[(round(0.7*n)+1):n,]
  splits[[1]] = train
  splits[[2]] = test
  return(splits)
}

#this subsets the data into species
create_train_test = function(dataset){
  sets = as.character(unique(dataset[,1]))
  train = data.frame()
  test = data.frame()
  split_data = list()
  for (i in 1:length(sets)){
    sub = subset(dataset, dataset[,1] == sets[i])
    train_temp = shuffle(sub)[[1]]
    test_temp = shuffle(sub)[[2]]
    train = rbind(train, train_temp)
    test = rbind(test, test_temp)
  }
  split_data[[1]] = train
  split_data[[2]] = test
  return(split_data)
}

#PS you can check the splits are correct with summary(train$species), summary(test$species)
#summary(maindata$species), this gives numbers in each species.

#now to include a cross fold validation repeat above fold times

```

```{r}
repeated_kmeans = function(dataset){ 
  metrics_list = list()
  accuracy_vector = vector()
  ratio = vector()
  species_no = data.frame(matrix(ncol = 7))
  colnames(species_no) = speciesnames
  for (i in 1:10){
    kmeans_result = kmeans(dataset[-1], 7, 20, iter.max = 50, algorithm = "MacQueen")
    ratio[i] = round(kmeans_result$tot.withinss/kmeans_result$totss, digits = 2)
    kmeans_conf = table(Imputed_df$Species, kmeans_result$cluster)
    accuracy_vector[i] = accuracy(kmeans_conf)
    species = diag(kmeans_conf)
    species_no = rbind(species_no, species)
  }
 metrics_list[[1]] = ratio
 metrics_list[[2]] = accuracy_vector
 metrics_list[[3]] = species_no[-1,]
 return(metrics_list)
}
```


```{r}
#Imputed df without scaling
Imputed_kmeans = repeated_kmeans(Imputed_df) 
#Semi scaled data
Semi_scaled_kmeans = repeated_kmeans(Semi_Scaled_df)
# fully scaled data
Scaled_kmeans = repeated_kmeans(Scaled_df)
```
Within cluster sum of squares/between cluster sum of squares for the unscaled, semi-scaled and fully scaled data for ten repeats of kmeans.
```{r}
#Looking at the results
SS_df = data.frame(nrow = 3)
SS_df = rbind(Imputed_kmeans[[1]],Semi_scaled_kmeans[[1]],Scaled_kmeans[[1]])
rownames(SS_df) = c("unscaled","semi-scaled","fullyscaled")
SS_df
```
The ratio is largest for the scaled data and does not decrease when the data is scaled, so an unscaled data set is preferable. The ratio is identical each time.

The accuracy over the ten repeats.
```{r}
#Looking at the results
prec_df = data.frame(nrow = 3)
prec_df = rbind(Imputed_kmeans[[2]],Semi_scaled_kmeans[[2]],Scaled_kmeans[[2]])
rownames(prec_df) = c("unscaled","semi-scaled","fullyscaled")
prec_df
```
The accuracy is different for each repeat on all the data sets, suggesting that the algorithm is not successfully clustering the data.

The next tables show the percentage of each species correctly allocated to its cluster on each of the ten repeats. For example, the top row from left to right, gives the true positive rate for S. anglia on each subsequent run on the kmeans algorithm.

```{r}
#Looking at the results
m1 = Imputed_kmeans[[3]]
m2 = Semi_scaled_kmeans[[3]]
m3 = Scaled_kmeans[[3]]


m1_percent = round(apply(m1, 1, function(x) (x/numspecies)*100), digits = 2)
colnames(m1_percent) = c(1:10)
cat("unscaled")
m1_percent
cat("\n")

m2_percent = round(apply(m2, 1, function(x) (x/numspecies)*100), digits = 2)
colnames(m2_percent) = c(1:10)
cat("semi-scaled")
m2_percent
cat("\n")

m3_percent = round(apply(m3, 1, function(x) (x/numspecies)*100), digits = 2)
colnames(m3_percent) = c(1:10)
cat("scaled")
m3_percent
cat("\n")

```

The results again show that the algorithm is not consistently allocating species to the correct cluster. On some runs, is is very accurate for some species, but not necessarily for all the others. Then on other runs its is completely inaccurate.

Hierarchical Clustering.

First the unscaled imputed data.

```{r}
repeated_hclust = function(dataset){
  conf = list()
  metrics_list = list()
  accuracy_vector = vector()
  dist_methods = c("euclidean", "maximum","manhattan","canberra","minkowski")
for (i in 1:length(dist_methods)){
  method = dist_methods[i]
  distance = dist(dataset[-1], method = method)
  hcluster = hclust(distance, method = "complete")
  cluster = cutree(hcluster, k = 7)
  conf[[i]] = table(dataset$Species, cluster)
  accuracy_vector[i] = accuracy(conf[[i]])
}
  accuracy_df = rbind(dist_methods, accuracy_vector)
  metrics_list[[1]]=accuracy_df
  metrics_list[[2]]=conf
  names(metrics_list)=c("Accuracy", "Confusion Matrix")
  return(metrics_list)

}

hcluster = repeated_hclust(Imputed_df)
accs = data.frame(nrow = 2)
accs = rbind(hcluster[[1]][1,], hcluster[[1]][2,])
rownames(accs) = c("Distance Method", "Accuracy")
colnames(accs) = c(" ", " "," ", " "," ")
cat("Accuracy obtained using the different distance calculations\n")
print(accs)
```

The canberra distance gives the most accurate results, below is the confusion matrix for that method

```{r}
hcluster[[2]][[4]]
```

The confusion matrix shows that whilst many S anglica and S minima were clustered together, many other species were dispersed across clusters. The model is not efficient in separting the species.

When the scaled date was used, the accuracy reduced. The results demonstrate that while hierarchical clustering was more accurate than kmeans when the canberra distance is used, the model is still very poor.

Decision Tree







