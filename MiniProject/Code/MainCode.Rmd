---
title: "MiniProject"
author: "PetraGuy"
date: "23 November 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
clear the workspace
```{r}

rm(list = ls())
cat("\014")
```
Get the data , enter input CSV file name here, for data in data directory
```{r}
inputfile = 'SorariaCompact1.csv'
Dataname = strsplit(inputfile, "\\.")[[1]][[1]]
fullfile = paste("../Data",inputfile,sep = '/')
Data = read.csv(fullfile)
```

Do some median imputations if necessary
```{r}
median_replace1 = function(x){
  ifelse(is.na(x), median(x,na.rm = TRUE), x)
 }

median_replace2 = function(x){
  apply(x,2,median_replace1)
}

Imputed_list = lapply(split.data.frame(Data[,2:12], Data$Species), FUN = median_replace2)
```

The imputed dataframe is a list with species as the elements, the following sticks it back together with a different name so both optiona are available

```{r}
temp = do.call(rbind, Imputed_list)
Imputed_df = cbind(Data[1], temp)
```

Its worth creating a scaled dataframe too for some of the analysis and ploting
```{r}
Scaled_df = scale(Imputed_df[-1])
Scaled_df = cbind(Data[1], Scaled_df)
```


PLOTTING

Execute the first section to save the data, or go straight to plotting to view graphs in document
```{r}
out = paste(Dataname, "pairs", sep = "_")
out= paste('../Results',out,sep = '/')
out = paste(out,'.pdf')

```
Pairs Plots, unhash pdf to save data to file. Not all pairs plotted beacuse there are so many the plot becomes too difficult to read and therefore uninformative. The pairs plot

```{r}
#pdf(out)
reduced_df = Imputed_df[-c(4,5,6,7,8,9,12)]
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r <- abs(cor(x, y))
  txt <- format(c(r, 0.123456789), digits = digits)[1]
  txt <- paste0(prefix, txt)
  if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
  text(0.5, 0.5, txt, cex = cex.cor * r)
}
pairs(reduced_df[-1], lower.panel = panel.smooth, upper.panel = panel.cor, col = Imputed_df$Species)
mtext(Dataname, side = 1)
```

Repeat the pairs plots using ggplot

```{r}
library(GGally)
ggpairs(data = Imputed_df[,2:6])

ggpairs(Imputed_df[,7:12])
```



Look at scatter plots by species of main characters, run the following to get new filename if saving data
```{r}
out = paste(Dataname, "scatter", sep = "_")
out= paste('../Results',out,sep = '/')
out = paste(out,'.pdf')

```

Scatter plots, unhash pdf to save data to file

```{r}
library(ggplot2)
library(gridExtra)
#pdf(out)
graphics.off()
reduced_df = Imputed_df[Imputed_df$Species == "Arranensis",]
ggplot(reduced_df,aes(x= LeafLength, y = LeafWidth)) +
                 geom_point()
plot1= ggplot(Imputed_df , aes(x= LeafLength, y = LeafWidth, col = Species))+
  geom_point()
plot2 = ggplot(Imputed_df, aes(x= FruitLength, y = FruitWidth, col = Species))+
  geom_point()

grid.arrange(plot1,plot2)
```

Box plots
```{r}
out = paste(Dataname, "box", sep = "_")
out= paste('../Results',out,sep = '/')
out = paste(out,'.pdf')
```


```{r}
#pdf(out)
col_names = colnames(Data)
col_names = col_names[-1]
plotlist = list()
library(grid)
for (i in seq_along(col_names)){
  plot = ggplot(Imputed_df, (aes_string(x='Species', y=col_names[i])))+
                 geom_boxplot()
  plotlist = rbind(plotlist,  plot)
  grid.draw(plot)
}

```

Try ggplot option for boxplots, but they'll need scaling because facet wrap will use same scale for all

```{r}
out = paste(Dataname, "scaledbox", sep = "_")
out= paste('../Results',out,sep = '/')
out = paste(out,'.pdf')
```


```{r}
#pdf(out)
library(reshape2)
melted = melt(Scaled_df)

ggplot(data = melted) +  geom_boxplot(aes(x=Species,y=value, fill = Species)) +   facet_wrap(~variable) +
  theme(axis.ticks = element_blank(), axis.text.x = element_blank())
```

Th scatter plots and pairs plots indicate that only leaf length, leaf width and widest point are correlated with a correlation coefficient of 0.9. Two of these variables might then be removed from the analysis.

Lets look at anovas for each feature
```{r}
out = paste(Dataname, "anova", sep = "_")
out= paste('../Results',out,sep = '/')
out = paste(out,'.csv')

```


```{r}

col_names = colnames(Data)
col_names = col_names[-1]
anova_data = data.frame()

for (i in seq_along(col_names)){
    m = lm(formula = paste(col_names[i],"~Species"), data =  Imputed_df)
    ANOVA <- anova(m)
    r2 <- summary(m)$r.squared
    data = data.frame(col_names[i], ANOVA[[4]][1], ANOVA[[5]][1], r2)
    anova_data = rbind(anova_data,data)
    
    
  }
names(anova_data) = c("Feature","F", "p", "r2")
print(anova_data)
write.csv(anova_data, out)
```

But what happens if we need to scale the data, repeated anovas for scaled dataframe

```{r}
out = paste(Dataname, "anova_scaled", sep = "_")
out= paste('../Results',out,sep = '/')
out = paste(out,'.csv')
```

```{r}
col_names = colnames(Data)
col_names = col_names[-1]
anova_data = data.frame()

for (i in seq_along(col_names)){
    m = lm(formula = paste(col_names[i],"~Species"), data =  Scaled_df)
    ANOVA <- anova(m)
    r2 <- summary(m)$r.squared
    data = data.frame(col_names[i], ANOVA[[4]][1], ANOVA[[5]][1], r2)
    anova_data = rbind(anova_data,data)
    
    
  }
names(anova_data) = c("Feature","F", "p", "r2")
print(anova_data)
write.csv(anova_data, out)
```

It looks like there is a difference with within group means and between group means, as we can see from the large F values, except in WidestPercent. LeafWidth, LeafLength and WidestPoint are highly correlated and may not all be requried in a model

Some simple cluster analysis
```{r}
set.seed(1)
library(ggplot2)
library(gridExtra)
graphics.off()

Imputed_kmeans = kmeans(Imputed_df[-1], 7)
table(Imputed_df$Species, Imputed_kmeans$cluster)

plot1= ggplot(Imputed_df, aes(x= LeafLength, y = LeafWidth, col = Imputed_kmeans$cluster))+
  geom_point()

plot2= ggplot(Imputed_df, aes(x= LeafLength, y = LeafWidth, col = Species))+
  geom_point()

grid.arrange(plot1,plot2)
```
What about principle components?

```{r}
pc = princomp(Scaled_df[-1])
plot(pc)
plot(pc, type = 'l')

```

```{r}
pc = prcomp(Scaled_df[-1])
comp = data.frame(pc$x[,1:4])
plot(comp)
loadings = eigen(cov(Scaled_df[-1]))$vectors
explvar = round((loadings^2),digits = 2)
rownames(explvar) =  col_names
print(explvar)

```
If leaf length is correlated with width and widest point and leaf width, AND pc shws that leafwidth, veins, leaf ratio, fruit length and widest percent together explain 80% of the variance, perhaps a model using only these is sufficient.

```{r}
reduced_data = Imputed_df[-c(1,2,4,5,8,11,12)]
Imputed_kmeans = kmeans(reduced_data, 7, nstart = 7)
table(Imputed_df$Species, Imputed_kmeans$cluster)
```



Supervised Learning 
Create training and test sets. Cross validation will be used to train the model. The caret package is need to do this within the model fitting algorithm, otherwise you would need to write your own for loops for each fold of cross validation.

```{r}

```


Classification 
Random forest - many decision trees fittied by repeated bootstrapping.

```{r}
library(caret)
set.seed(42)
forest = train(Species~., data = Imputed_df, method = "ranger",
               trControl= trainControl(method = "cv", number = 5))
plot(forest)
print(forest)



```







