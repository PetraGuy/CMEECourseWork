---
title: "HPC Coursework"
author: "PetraGuy"
date: "4 December 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r, echo=FALSE}

rm(list = ls())
graphics.off()

#generate random communities
generate_community = function(n,seed) {
  set.seed(seed)
  comm = sample(x = c(1:10),
                size = n,
                replace = TRUE)
  return(comm)
}

#Q1 get species richness
species_richness = function(x) {
  r = length(unique(x))
  return(r)
}

#Q2 Get a maximally diverse community
initialise_max = function(x) {
  comm = seq(1:x)
  return(comm)
}

#Q3 get a minimally diverse community - everything is the same
initialise_min = function(x) {
  comm = rep(1, x)
  return(comm)
}


#Q4 Need for neutral_step functions, just select two numbers from within the length of
#input vector which can then be used as indices for speciation or death replacement
choose_two = function(x) {
  two = sample(x, 2)
  return(two)
}

#Q5 Uses choose two and then replaces species at index 1 with that at index 2
#Simulates a species dieing and being repalced by another within community
neutral_step = function(x) {
  index = choose_two(length(x))
  x[index[1]] = x[index[2]]
  return(x)
}

#Q6 Su=imulates n steps of neutral step
neutral_generation = function(x) {
  n = round(length(x) / 2)
  for (i in 1:n) {
    comm = neutral_step(x)
  }
  return(comm)
}


#Q7 Runs several generations and returns species richness a each step
neutral_time_series = function(x, t) {
  rich = (species_richness(x))
  for (i in 1:t) {
    x = neutral_generation(x)
    rich = c(rich, species_richness(x))
    
  }
  return(rich)
}

#Q8 Uses neutral time series over 200 steps on a maximally diverse community and plots the richness
question_8 = function() {
  rich = neutral_time_series(initialise_max(100), 2000)
  plot(rich, main = "Species richness without new species",
       ylab = "species richness",
       xlab = "time steps")
}
```

```{r}
question_8()
```


The graph plots species richness of a community starting with 100 different species over 2000 generations. In this model new species are not introduced, so each step wither maintains the richness or reduces it. For example, if you begin with a community (1,2,3,4,5), one step could change this to (2,2,3,4,5) At the next step he community will either remain unchanged, or be reduced, for example (2,2,3,3,5). Since there is no mechanism to increase species richness, eventually, given enough steps, the richness will become 1.


```{r, echo = FALSE}
#Q9 creates a neutral step with either a speciation or a replacement, depending on value of v
neutral_step_speciation = function(x, v) {
  p = runif(1)
  if (v < p) {
    index = choose_two(length(x))
    x[index[1]] = x[index[2]]
  }
  else {
    newspecies =  max(x) + 1
    index = sample((length(x)), size = 1, replace = TRUE)
    x[index] = newspecies
  }
  return(x)
}

#Q10 Takes a community and outputs new community after a few generations with speciation or replacement
neutral_generation_speciation = function(x, v) {
  n =  round(length(x) / 2)
  for (i in 1:n) {
    x = neutral_step_speciation(x, v)
  }
  return(x)
}

#Q11 Returns community richness at each generation
neutral_time_series_speciation = function(x, v, t) {
  rich = vector()
  for (i in 1:t) {
    x = neutral_generation_speciation(x, v)
    rich[i] = species_richness(x)
  }
  return(rich)
}
```


```{r, echo=FALSE}
question_12 = function() {
  t = 200
  v = 0.1
  comm_max = initialise_max(100)
  comm_min = initialise_min(100)
  rich_max = neutral_time_series_speciation(comm_max, v, t)
  rich_min = neutral_time_series_speciation(comm_min, v, t)
  
  x = (1:t)
  titles = c("Max", "Min")
  y =  cbind(rich_max, rich_min)
  colnames(y) = titles
  
  matplot (x, y, pch = 19, col = 1:2, main = "Species richness over time with speciation")
  
  legend(1,
         50,
         legend = colnames(y),
         col = 1:2,
         lty = 1:4)
}
```

```{r}
question_12()
```

The graph shows the species richness for two communities, one with maximum richness, one with minimum, both with 100 individuals and a speciation reate of 0.1.
Because the speciation rate is the same both communities they tend to the same richness after sufficient generations. A richness of around 30 after 50 generations in this case.
The higher the speciation rate, the greater the richness of the final community, because the algorithm will more refrequently follow the step of generating a new individual. The final community richness depends on the speciations rate and the size of the initial community - as the graphs below show

```{r}
question_12b = function() {
  t = 200
  
  v = 0.1
  comm_max = initialise_max(100)
  comm_min = initialise_min(100)
  rich_max = neutral_time_series_speciation(comm_max, v, t)
  rich_min = neutral_time_series_speciation(comm_min, v, t)
  y1 =  cbind(rich_max, rich_min)
  
 
  v = 0.9
  comm_max = initialise_max(100)
  comm_min = initialise_min(100)
  rich_max = neutral_time_series_speciation(comm_max, v, t)
  rich_min = neutral_time_series_speciation(comm_min, v, t)
  y2 =  cbind(rich_max, rich_min)
  

  v = 0.1
  comm_max = initialise_max(500)
  comm_min = initialise_min(500)
  rich_max = neutral_time_series_speciation(comm_max, v, t)
  rich_min = neutral_time_series_speciation(comm_min, v, t)
  y3 =  cbind(rich_max, rich_min)
  
 
  v = 0.1
  comm_max = initialise_max(1000)
  comm_min = initialise_min(1000)
  rich_max = neutral_time_series_speciation(comm_max, v, t)
  rich_min = neutral_time_series_speciation(comm_min, v, t)
  y4 =  cbind(rich_max, rich_min)
  
  x = (1:t)
  par(mfrow=c(2,2))
  
  matplot (x, y1, pch = 19, col = 1:2, main = "v = 0.1, size = 100")
  
  matplot (x, y2, pch = 19, col = 1:2, main = "v = 0.9, size = 100")
 
  matplot (x, y3, pch = 19, col = 1:2, main = "v = 0.1, size = 500")
  
  matplot (x, y4, pch = 19, col = 1:2, main = "v = 0.1, size = 1000")
  
  
}

```

```{r}
question_12b()
```
For  community size of 100, the final species richness is around 30 for v = 0.1 and nearly 100 for v = 0.9. If the inital community size is increased to 500, the final richness increases to around 75, and for an inital community of 1000, the final richness is around 125.


```{r, echo=FALSE}
#Q13 calcualte species abundance using table - which gives frequencies
species_abundance = function(x) {
  abundance = as.numeric(sort(table(x), decreasing = TRUE))
  return(abundance)
}
#Q14 Arrange the abundances into octets
octaves = function(x) {
  oct = tabulate(floor(log2(x)) + 1)
  return(oct)
}
#Q15 Need to add the octets produced by octaves() and average them, but each octet can be a different
#length, this function pads the shorter octet with zeros
sum_vect = function(x, y) {
  if (length(x) < length(y))    {
    short = x
    long = y
    newshort = c(x, rep(0, length(long) - length(short)))
    sum = newshort + long
  }   else if (length(x) > length(y)) {
    short = y
    long = x
    newshort = c(y, rep(0, length(long) - length(short)))
    sum = newshort + long
  }   else  {
    sum = x + y
  }
  return(sum)
}
```


```{r, echo=FALSE}

#Q16, produce a barchart of octets after 200 generations burn-in, using another 2000 generations
#using v = 0.1, size = 100

question_16 = function() {
  octets = list()
  x = initialise_min(100)
  v = 0.1
  rich = vector()
  i = 1
  index = 1
  # burn in
  while (i < 2200) {
    if (i < 200) {
      x = neutral_generation_speciation(x, v)
      
    } else {
      # continue for 2000 cycles
      x = neutral_generation_speciation(x, v)
      if (i %% 20 == 0) {
        abundance = species_abundance(x)
        octets[[index]] = octaves(abundance)
        index = index + 1
      }
      
    }
    i = i + 1
  }
  
  #find the average of the octaves which are list elements of octets
  l = length(octets)
  sum = vector()
  for (a in 1:(l)) {
    sum = sum_vect(sum, octets[[a]])
    
    
  }

  ave = sum / l
  names = names = c("1", "2,3", "4 -7", "8-31", "32-63", ">64")
  barplot(ave,
          names.arg = names,
          main = "Average abundances in octets",
          xlab = "abundances")

}

```



```{r}
question_16()
```

The graph shows the average abundances of the community after the burn-in of 200 generations. The distribution of abundances would change if the speciation rate changed. A higher speciation rate would result in a richer community and therefore the first octet would have a higher frequency. A low speciation rate results in a community of low richness and therefore the frequencies of the larger octets increase at the expense of the smaller. As we saw bove, a large initial community would also result in higher richness and larger first octet.

```{r,echo=FALSE}
get_series_average = function(richness_vector){
  avg = vector()
  avg = c(avg,richness_vector[1])
  for ( i in 1:(length(richness_vector)-1)){
    i = i + 1
    tmpvect = richness_vector[1:i]
    total = sum(tmpvect)
    avgerage = total/length(tmpvect)
    avg= c(avg, avgerage)
  }
  return(avg)
}
```

```{r, echo=FALSE}
 
challenge_A = function(){
t = 200
v = 0.1
repeats = 500

#get two starting communities
comm_max = initialise_max(100)
comm_min = initialise_min(100)

#initialise richness vector
richness_max_vect = vector(length = t)
richness_min_vect = vector(length = t)

#initialise df for storing output for laer calculations
richness_df_max = data.frame()
richness_df_min = data.frame()


for (i in 1:repeats) {
  
  #get times series of richness for them both - repeat this and store values for each repeat
  rich_max = neutral_time_series_speciation(comm_max, v, t)
  rich_min = neutral_time_series_speciation(comm_min, v, t)
  
  richness_df_max = rbind(richness_df_max,rich_max)
  richness_df_min = rbind(richness_df_min,rich_min)
  
  
}
#can be useful to name cols - otherwise first row can become a header
cols = c(1:t)
colnames(richness_df_max) = cols
colnames(richness_df_min) = cols
#calcualte the standard deviations and averages using the dataframe of stored richnesses
#because each run is a row the cols are used for sd and ave.
sd_max = sqrt(apply(richness_df_max,2,var))
sd_min = sqrt(apply(richness_df_min,2,var))
avg_max = colSums(richness_df_max)/repeats
avg_min = colSums(richness_df_min)/repeats

#for 97.2% CI we need 98.6th percentile = z of 2.2
CI_upper_max = avg_max + 2.2*sd_max
CI_lower_max = avg_max - 2.2*sd_max

CI_upper_min = avg_min + 2.2*sd_min
CI_lower_min = avg_min - 2.2*sd_min

#plot the graphs

x = (1:t)
titles = c("Maximum initial richness", "Minimum initial richness")
y =  cbind(avg_max, avg_min)

matplot (x, y, pch = 20, col = 1:2, xlim = c(0,t), ylim = c(0,100),
         xlab = "time", ylab = "Average species richness",
         main = "Average species richness for 500 repeats of neutral_time_series_speciation, initial community size 100")
legend(50,
       100,
       legend = titles,
       col = 1:2,
       lty = 1:4)

lines(CI_upper_max)
lines(CI_lower_max)
lines(CI_upper_min, col = "red")
lines(CI_lower_min, col = "red")

}
```

```{r}
challenge_A()
```

The graph is a plot of average richness values as the times increments. The 97.2% confidence inervals were calculated using z = 2.2 giving the 98.6th percentile - giving 1.4% in each tail. Dynamic equilibrium is reached at around 50 steps. 

```{r, echo = FALSE}
challenge_B = function(){
  
  v = 0.1
  t = 200
  size = 100
  repeats = 50
  num_communties = 10
  
  communities = data.frame(row.names = FALSE)
  
  #generate some communites with random initial richnesses and store them
  #in a datframe called communties. Because expected richness for 100 selected
  #from 100 is 63.66, richness will always be around 64. To get a variety of richnesses
  # the number out of wich to select is altered
  for (i in 1:num_communties){
    set.seed(i)
    m = size/i
    community = generate_community(m,size)
    communities = cbind(communities, community,row.names = NULL)
   
  }
  
  #create a list of dataframes of richnesses for each community in communities
  #when is is processes through neutral_time_series_speciation repeat times
  
  richness_list = list()
  
  get_repeated_richnesses = function(a_comm,v,t){
    richness_df = data.frame()
    for (i in 1:repeats){
    richness = neutral_time_series_speciation(a_comm, v, t)
    richness_df = rbind(richness_df,richness,row.names = NULL)
    }
    return(richness_df)
  }
  
  for (i in 1:num_communties){
      richness_list[[i]] = get_repeated_richnesses(communities[,i],v,t)
  }
  
# we now have richness_list. Each element is a num repeats x t dataframe for each 
#initial community. Each row of the datafram is the richness value through time.
# There as many rows as we specified repeats to average over. As for challenge A
#we now take the  average for each column to give an average richness 
#over the time steps. No CI required this time
  ave_df =  data.frame(row.names = FALSE)
  for (i in 1:num_communties){
    ave = colSums(richness_list[[i]])/repeats
    ave_df = cbind(ave_df,ave, row.names = NULL)
  }
    
  x = (1:t)
  matplot (x, ave_df, pch = 19, cex = 0.3,
           xlab = "generations", ylab = "average richness", 
           main = "Average species richness for various starting communities",
           sub = "v = 0.1, community size = 100")
  
}

```


```{r}
challenge_B()
```



```{r, echo = FALSE}
############# Question 20 ##########################################
# Read in the files from the HPC
#couldnt work out easy wy of specifying files in each batch, so this first function
get_quartile = function(i) {
  if (i == 1) {
    quartile = c(1:24)
  }
  else if (i == 2) {
    quartile = c(27:49)
  }
  else if (i == 3) {
    quartile = c(52:74)
  }
  else {
    quartile = c(77:100)
  }
  return(quartile)
}

# This function returns the sum and number of the octets in single file, to be found in path specified
get_sum_and_length_of_octet = function(i) {
  #browser()
  infile = paste("../Results/Cluster_1207/pg5117/pg5117_cluster_", i, ".rda", sep = "")
  load(infile)
  len = length(octets)
  sum = vector()
  sum_and_length = list()
  for (a in 1:len) {
    sum = sum_vect(sum, octets[[a]])
  }
  sum_and_length[[1]] = sum
  sum_and_length[[2]] = len
  return(sum_and_length)
  
}


get_results = function() {
  #browser()
  ave_for_file_batch = list()
  for (i in 1:4) {
    j = get_quartile(i)    # this return vector of file numbers in each batch, eg if i = 2, 26:50
    cum_sum = vector()
    cum_len = 0
    results = list()
    for (counts in j) {
      results =  get_sum_and_length_of_octet(counts)
      cum_sum = sum_vect(cum_sum, results[[1]])
      cum_len =  results[[2]] + cum_len
    }
    ave_for_file_batch[[i]] = cum_sum / cum_len
    
  }
  return(ave_for_file_batch)
}

plot_results = function(results) {
  par(mfrow = c(2, 2))
  ave1 = results[[1]]
  #names = names = c("1", "2", "3", "4", "5", "6","7","8","9")
  plot1 = barplot(ave1,
                  #names.arg = names,
                  main = paste(round(results[[1]],3),collapse=","), cex.main = 0.75,
                  xlab = "abundances")
  ave2 = results[[2]]
  #names = names = c("1", "2", "3", "4", "5", "6","7","8","9","10")
  plot2 = barplot(ave2,
                  #names.arg = names,
                  main = paste(round(results[[2]],3),collapse=","),cex.main = 0.75,
                  xlab = "abundances")
  ave3 = results[[3]]
  #names = names = c("1", "2", "3", "4", "5", "6","7","8","9","10","11","12")
  plot3 = barplot(ave3,
                  #names.arg = names,
                  main = paste(round(results[[3]],3),collapse=","),cex.main = 0.75,
                  xlab = "abundances")
  ave4 = results[[4]]
  #names = names = c("1", "2", "3", "4", "5", "6","7","8","9","10","11","12","13")
  barplot(ave4,
          #names.arg = names,
         main = paste(round(results[[4]],3),collapse=","),cex.main = 0.75,
          xlab = "abundances")
}
results = get_results()
plot_results(results)

```





```{r, echo = FALSE}
### Coalescence simulation 
Challengne_D = function() {
  sizes  = c(500, 1000, 2500, 5000)
  v = 0.002125
  
  Abundances = list()
  
  for (i in 1:4) {
    size = sizes[i]
    theta = 0.002125 * (size - 1) / (1 - v)
    abundance = vector()
    lineages = initialise_min(size)
    N = length(lineages)
    
    while (N > 1) {
      p = theta / (theta + N - 1)
      r = runif(1, 0:1)
      index = sample(N, 2)
      
      if (r < p) {
        abundance = c(abundance, lineages[index[1]])
      }
      else {
        lineages[index[1]] = lineages[index[1]] + lineages[index[2]]
        lineages = lineages[-index[2]]
      }
      N = length(lineages)
    }
    
    abundance = c(abundance, lineages)
    Abundances[[i]] = abundance
  }
  return(Abundances)
}
Abundances = Challengne_D()
octets = list()
for (i in 1:4){
octets[[i]]= octaves(Abundances[[i]])

}
  par(mfrow = c(2, 2))
  y1 = octets[[1]]
  #names = names = c("1", "2", "3", "4", "5", "6","7","8","9")
  plot1 = barplot(y1,
                  #names.arg = names,
                  main = "Average abundances in octets",
                  xlab = "abundances")
  y2 = octets[[2]]
  #names = names = c("1", "2", "3", "4", "5", "6","7","8","9","10")
  plot2 = barplot(y2,
                  #names.arg = names,
                  main = "Average abundances in octets",
                  xlab = "abundances")
  y3 = octets[[3]]
  #names = names = c("1", "2", "3", "4", "5", "6","7","8","9","10","11","12")
  plot3 = barplot(y3,
                  #names.arg = names,
                  main = "Average abundances in octets",
                  xlab = "abundances")
  y4 = octets[[4]]
  #names = names = c("1", "2", "3", "4", "5", "6","7","8","9","10","11","12","13","14","15")
  barplot(y4,
          #names.arg = names,
          main = "Average abundances in octets",
          xlab = "abundances")


```


These are the octets from the coalescence simulation, which look very similar to the results of the simulation from the HPC (!).
Not totally sure why one is quiker - except that in the coalescence model you generate one community, then do the size of the community calculations, so for our sizes,that's a maximum of 10,000 cyles in the loop. For the neutral model you generate a new community of size N many times during the burn in, then you continue recreating new communities for the presest time in order to take an average over all the cyles. Therefore there are many more calculations. 

Question 18

The fractal dimension,D is given by

$$ D = \frac{\log(N)}{\log(r)}$$
N is the number of new shapes produced when you divide the original by r. So for the Menger gasket which starts as 1 solid square, cutting the sides into 3 parts results in 8 solid squares. The fractal dimension is therefore

$$ D = \frac{\log(8)}{\log(3)} = 1.893$$
In the Menger sponge, you start with a sold cube, cutting the sides ino 3 results in 20 smaller cubes, so the dimension is 
$$ D = \frac{\log(20)}{\log(3)} = 2.727$$
```{r, echo=FALSE}
chaos_game = function(){
  graphics.off()
  #browser()
  x = vector()
  y = vector()
  X <- list(c(0,0),c(3,4),c(4,1))
  coord = X[[1]]
  x1 = coord[[1]]
  y1 = coord[[2]]
  plot(NA, xlim=c(0,5), ylim=c(0,5), xlab="X", ylab="Y")
  points(x1,y1, cex = 0.2)
  for (i in 1:1000){
   index = sample((1:3),1)
   coord = X[[index]]
   x2 = coord[[1]]
   y2 = coord[[2]]
   x1 = (0.5*x2 + 0.5*x1)
   y1 = (0.5*y2 + 0.5*y1)
   x = c(x, x1)
   y = c(y, y1)
  
  }
  plot(x , y, cex = 0.2)
}
```

```{r}
chaos_game()
```

The code produces a Sierpinski Gasket type picture.

```{r, echo=FALSE}

plot(NA, xlim=c(0,1), ylim=c(0,1), xlab="X", ylab="Y")

turtle = function(start, distance, direction){
  x1 = start[1]
  y1 = start[2]
  x2 = x1 + distance*cos(direction)
  y2 = y1 + distance*sin(direction)
  segments(x1,y1,x2,y2)
  coords = c(x2,y2)
  return(coords)
}

spiral = function(start, distance, direction){
  coords = turtle(start, distance, direction)
  
  if (distance > 0.1){
    #direction = -1* (pi - direction - pi/4)
    distance = 0.95*distance
    spiral(coords,distance = 0.95*distance, direction = (-1* (pi - direction - pi/4)))
  
}
}
spiral(c(0,0),1,1)
```
Q22 Fractals.
The code produces a spiral, but includes a nested, recurssive loop because it continually calls itself. Putting an if (distance > 0.1) statement before calling spiral within spiral ensure that the programme will stop.

```{r, echo=FALSE}
graphics.off()



tree = function(start, distance, direction) {
  coords = turtle(start, distance, direction)
  #coords = turtle(start, distance, direction)
    if (distance > 0.1){
    distance = 0.65*distance
    tree(coords, distance= 0.65*distance, direction = (pi/4) ) 
    tree(coords, distance= 0.65*distance, direction = (3*pi/4) ) 
    }
}


```

```{r}
plot(NA, xlim=c(0,50), ylim=c(0,50), xlab="X", ylab="Y")
tree(c(25,0),30,1.5)
```


```{r, echo=FALSE}
graphics.off()



fern = function(start, distance, direction) {
  coords = turtle(start, distance, direction)
  distance1 = distance
  distance2 = distance
  #coords = turtle(start, distance, direction)
  if (distance > 0.01){
    distance = 0.9*distance
    fern(coords, distance = 0.38*distance1, direction = 3*pi/4 ) 
    fern(coords, distance= 0.87*distance2, direction = (pi/2) ) 
  }
}

```

```{r}
plot(NA, xlim=c(0,2), ylim=c(0,10), xlab="X", ylab="Y")
fern(c(1,0),1,1)
```





```{r, echo = FALSE}

```


