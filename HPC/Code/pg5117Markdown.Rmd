---
title: "HPC Coursework"
author: "PetraGuy"
date: "4 December 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r, echo=FALSE}

rm(list = ls())
graphics.off()

#generate random communities
generate_community = function(n,seed) {
  set.seed(seed)
  comm = sample(x = c(1:10),
                size = n,
                replace = TRUE)
  return(comm)
}

#Q1 get species richness
species_richness = function(x) {
  r = length(unique(x))
  return(r)
}

#Q2 Get a maximally diverse community
initialise_max = function(x) {
  comm = seq(1:x)
  return(comm)
}

#Q3 get a minimally diverse community - everything is the same
initialise_min = function(x) {
  comm = rep(1, x)
  return(comm)
}


#Q4 Need for neutral_step functions, just select two numbers from within the length of
#input vector which can then be used as indices for speciation or death replacement
choose_two = function(x) {
  two = sample(x, 2)
  return(two)
}

#Q5 Uses choose two and then replaces species at index 1 with that at index 2
#Simulates a species dieing and being repalced by another within community
neutral_step = function(x) {
  index = choose_two(length(x))
  x[index[1]] = x[index[2]]
  return(x)
}

#Q6 Su=imulates n steps of neutral step
neutral_generation = function(x) {
  n = round(length(x) / 2)
  for (i in 1:n) {
    comm = neutral_step(x)
  }
  return(comm)
}


#Q7 Runs several generations and returns species richness a each step
neutral_time_series = function(x, t) {
  rich = (species_richness(x))
  for (i in 1:t) {
    x = neutral_generation(x)
    rich = c(rich, species_richness(x))
    
  }
  return(rich)
}

#Q8 Uses neutral time series over 200 steps on a maximally diverse community and plots the richness
question_8 = function() {
  rich = neutral_time_series(initialise_max(100), 2000)
  plot(rich, main = "Species richness without new species",
       ylab = "species richness",
       xlab = "time steps")
}

#Q9 creates a neutral step with either a speciation or a replacement, depending on value of v
neutral_step_speciation = function(x, v) {
  p = runif(1)
  if (v < p) {
    index = choose_two(length(x))
    x[index[1]] = x[index[2]]
  }
  else {
    newspecies =  max(x) + 1
    index = sample((length(x)), size = 1, replace = TRUE)
    x[index] = newspecies
  }
  return(x)
}

#Q10 Takes a community and outputs new community after a few generations with speciation or replacement
neutral_generation_speciation = function(x, v) {
  n =  round(length(x) / 2)
  for (i in 1:n) {
    x = neutral_step_speciation(x, v)
  }
  return(x)
}

#Q11 Returns community richness at each generation
neutral_time_series_speciation = function(x, v, t) {
  rich = vector()
  for (i in 1:t) {
    x = neutral_generation_speciation(x, v)
    rich[i] = species_richness(x)
  }
  return(rich)
}
```




```{r, echo=FALSE}
question_12 = function() {
  t = 200
  v = 0.1
  comm_max = initialise_max(100)
  comm_min = initialise_min(100)
  rich_max = neutral_time_series_speciation(comm_max, v, t)
  rich_min = neutral_time_series_speciation(comm_min, v, t)
  
  x = (1:t)
  titles = c("Max", "Min")
  y =  cbind(rich_max, rich_min)
  colnames(y) = titles
  
  matplot (x, y, pch = 19, col = 1:2, main = "Species richness over time with speciation")
  
  legend(1,
         50,
         legend = colnames(y),
         col = 1:2,
         lty = 1:4)
}
```



```{r, echo=FALSE}
#Q13 calcualte species abundance using table - which gives frequencies
species_abundance = function(x) {
  abundance = as.numeric(sort(table(x), decreasing = TRUE))
  return(abundance)
}
#Q14 Arrange the abundances into octets
octaves = function(x) {
  oct = tabulate(floor(log2(x)) + 1)
  return(oct)
}
#Q15 Need to add the octets produced by octaves() and average them, but each octet can be a different
#length, this function pads the shorter octet with zeros
sum_vect = function(x, y) {
  if (length(x) < length(y))    {
    short = x
    long = y
    newshort = c(x, rep(0, length(long) - length(short)))
    sum = newshort + long
  }   else if (length(x) > length(y)) {
    short = y
    long = x
    newshort = c(y, rep(0, length(long) - length(short)))
    sum = newshort + long
  }   else  {
    sum = x + y
  }
  return(sum)
}
```

```{r, echo=FALSE}

#Q16, produce a barchart of octets after 200 generations burn-in, using another 2000 generations
#using v = 0.1, size = 100

question_16 = function() {
  #browser()
  octets = list()
  x = initialise_min(100)
  v = 0.1
  rich = vector()
  i = 1
  index = 1
  # burn in
  while (i < 2200) {
    if (i < 200) {
      x = neutral_generation_speciation(x, v)
      
    } else {
      # continue for 2000 cycles
      x = neutral_generation_speciation(x, v)
      if (i %% 20 == 0) {
        abundance = species_abundance(x)
        octets[[index]] = octaves(abundance)
        index = index + 1
      }
      
    }
    i = i + 1
  }
  
  #find the average of the octaves which are list elements of octets
  l = length(octets)
  sum = vector()
  for (a in 1:(l)) {
    sum = sum_vect(sum, octets[[a]])
    
    
  }

  ave = sum / l
  names = names = c("1-3", "4-7", "8-31", "32-63", "64-127", ">127")
  barplot(ave,
          names.arg = names,
          main = "Average abundances in octets",
          xlab = "abundances")

}

```

```{r}
question_8()
```
The graph plots species richness of  community starting with maximum diversity of 100 species. The speciation rate is 0.1. In this model, new species are not introduces,therefore each step either maintains or reduces richness, so eventually the richness will decrease.
For example, if composition was initally 1,2,3,4,5, the next step must reduce richness to for example, 2,2,3,4,5. 
Another step will either maintain this, e.g. 5,2,3,4,5, or reduce it, 2,2,3,3,5.
There is not a mechanism in neutral step for increasing richness and therefore over many steps it will approach 1.

```{r}
question_12()

```

Question 12. Species richness as a time series over 200 generations. Speciation rate is 0.1 and maximal and minimal communities of 100 species were used. 
The speciation rate causes both communities to approach the same value after sufficient generations. In this simulation a species richness of approximately 30 is reached after around 50 generations. The higher the speciation rate, the richer the final community and vice versa.


```{r, echo=FALSE}
question_16()
```

The graph shows the average abundances of the community after the burn-in of 200 generations. The distribution of abundances would change if the speciation rate changed. A higher speciation rate would result in a richer community and therefore the first octet would have a higher frequency. A low speciation rate results in a community of low richness and therefore the frequencies of the larger octets increase at the expense of the smaller. 

```{r,echo=FALSE}
get_series_average = function(richness_vector){
  avg = vector()
  avg = c(avg,richness_vector[1])
  for ( i in 1:(length(richness_vector)-1)){
    i = i + 1
    tmpvect = richness_vector[1:i]
    total = sum(tmpvect)
    avgerage = total/length(tmpvect)
    avg= c(avg, avgerage)
  }
  return(avg)
}
```

```{r, echo=FALSE}
  
challenge_A = function() {
  t = 200
  v = 0.1
  #get two starting communities
  comm_max = initialise_max(100)
  comm_min = initialise_min(100)
  #get times series of richness for them both
  rich_max = neutral_time_series_speciation(comm_max, v, t)
  rich_min = neutral_time_series_speciation(comm_min, v, t)
  #get two sets of averages for the two richness vectors, then the for loop takes the average
  #as you increment along the richness vector
  avg_min = get_series_average(rich_min)
  avg_max = get_series_average(rich_max)
  
  #put averages in a dataframe
  x = (1:t)
  df = data.frame(max = avg_max, min = avg_min, time = x)
  #create confidence intervals from variance, only using values after the burn-in
  
  sd_max = sqrt(var(df$max[50:200]))
  sd_min = sqrt(var(df$min[50:200]))
  #for 97.2% CI we need 98.6th percentile = z of 2.2
  CI_upper_max = df$max + 2.2*sd_max
  CI_lower_max = df$max - 2.2*sd_max
  
  CI_upper_min = df$min + 2.2*sd_max
  CI_lower_min = df$min - 2.2*sd_max
  
  #plot the graphs
  titles = c("Max", "Min")
  y =  cbind(avg_max, avg_min)
  colnames(y) = titles
  matplot (x, y, pch = 16, col = 1:2,
           xlab = "generations", ylab = "average richness", main = "Average Species Richness")
  legend(1,
         50,
         legend = colnames(y),
         col = 1:2,
         lty = 1:4)
  
  #add the CIs
  lines(CI_upper_max)
  lines(CI_lower_max)
  lines(CI_upper_min, col = "red")
  lines(CI_lower_min, col = "red")
  
}
```

```{r}
challenge_A()
```

The graph is a plot of average richness values as the times increments. The confidence inervals were calcualted using the variance of the values from 50 to 100 increments. If the entire series was used, the confidence interval would be larger.

```{r, echo = FALSE}
challenge_B = function(){
  #browser()
  v = 0.1
  t = 200
  size = 100
  richness_matrix = matrix(nrow = 200)
  for (i in 1:10){
    seed = i
    community = generate_community(size,seed)
    richness = neutral_time_series_speciation(community,v,t)
    average_richness = get_series_average(richness)
    richness_matrix = cbind(richness_matrix,average_richness)
  }
  
  # plot the series
  x = (1:t)
  matplot (x, richness_matrix, pch = 16,
           xlab = "generations", ylab = "average richness", main = "Average Species Richness")
}

```
```{r}
challenge_B()
```

```{r, echo=FALSE}
chaos_game = function(){
  graphics.off()
  #browser()
  x = vector()
  y = vector()
  X <- list(c(0,0),c(3,4),c(4,1))
  coord = X[[1]]
  x1 = coord[[1]]
  y1 = coord[[2]]
  plot(NA, xlim=c(0,5), ylim=c(0,5), xlab="X", ylab="Y")
  points(x1,y1, cex = 0.2)
  for (i in 1:1000){
   index = sample((1:3),1)
   coord = X[[index]]
   x2 = coord[[1]]
   y2 = coord[[2]]
   x1 = (0.5*x2 + 0.5*x1)
   y1 = (0.5*y2 + 0.5*y1)
   x = c(x, x1)
   y = c(y, y1)
  
  }
  plot(x , y, cex = 0.2)
}
```

```{r}
chaos_game()
```

The code produces a Sierpinski Gasket type picture.

```{r, echo=FALSE}

plot(NA, xlim=c(0,1), ylim=c(0,1), xlab="X", ylab="Y")

turtle = function(start, distance, direction){
  x1 = start[1]
  y1 = start[2]
  x2 = x1 + distance*cos(direction)
  y2 = y1 + distance*sin(direction)
  segments(x1,y1,x2,y2)
  coords = c(x2,y2)
  return(coords)
}

spiral = function(start, distance, direction){
  coords = turtle(start, distance, direction)
  
  if (distance > 0.1){
    #direction = -1* (pi - direction - pi/4)
    distance = 0.95*distance
    spiral(coords,distance = 0.95*distance, direction = (-1* (pi - direction - pi/4)))
  
}
}
spiral(c(0,0),1,1)
```
Q22 Fractals.
The code produces a spiral, but includes a nested, recurssive loop because it continually calls itself. Putting an if (distance > 0.1) statement before calling spiral within spiral ensure that the programme will stop.

```{r, echo=FALSE}
graphics.off()



tree = function(start, distance, direction) {
  coords = turtle(start, distance, direction)
  #coords = turtle(start, distance, direction)
    if (distance > 0.1){
    distance = 0.65*distance
    tree(coords, distance= 0.65*distance, direction = (pi/4) ) 
    tree(coords, distance= 0.65*distance, direction = (3*pi/4) ) 
    }
}


```

```{r}
plot(NA, xlim=c(0,50), ylim=c(0,50), xlab="X", ylab="Y")
tree(c(25,0),30,1.5)
```


```{r, echo=FALSE}
graphics.off()



fern = function(start, distance, direction) {
  coords = turtle(start, distance, direction)
  distance1 = distance
  distance2 = distance
  #coords = turtle(start, distance, direction)
  if (distance > 0.01){
    distance = 0.9*distance
    fern(coords, distance = 0.38*distance1, direction = 3*pi/4 ) 
    fern(coords, distance= 0.87*distance2, direction = (pi/2) ) 
  }
}

```

```{r}
plot(NA, xlim=c(0,2), ylim=c(0,10), xlab="X", ylab="Y")
fern(c(1,0),1,1)
```

```{r, echo = FALSE}
### Coalescence simulation 
Challengne_D = function() {
  sizes  = c(500, 1000, 2500, 5000)
  v = 0.002125
  
  Abundances = list()
  
  for (i in 1:4) {
    size = sizes[i]
    theta = 0.002125 * (size - 1) / (1 - v)
    abundance = vector()
    lineages = initialise_min(size)
    N = length(lineages)
    
    while (N > 1) {
      p = theta / (theta + N - 1)
      r = runif(1, 0:1)
      index = sample(N, 2)
      
      if (r < p) {
        abundance = c(abundance, lineages[index[1]])
      }
      else {
        lineages[index[1]] = lineages[index[1]] + lineages[index[2]]
        lineages = lineages[-index[2]]
      }
      N = length(lineages)
    }
    
    abundance = c(abundance, lineages)
    Abundances[[i]] = abundance
  }
  return(Abundances)
}
Abundances = Challengne_D()
octets = list()
for (i in 1:4){
octets[[i]]= octaves(Abundances[[i]])

}
  par(mfrow = c(2, 2))
  y1 = octets[[1]]
  #names = names = c("1", "2", "3", "4", "5", "6","7","8","9")
  plot1 = barplot(y1,
                  #names.arg = names,
                  main = "Average abundances in octets",
                  xlab = "abundances")
  y2 = octets[[2]]
  #names = names = c("1", "2", "3", "4", "5", "6","7","8","9","10")
  plot2 = barplot(y2,
                  #names.arg = names,
                  main = "Average abundances in octets",
                  xlab = "abundances")
  y3 = octets[[3]]
  #names = names = c("1", "2", "3", "4", "5", "6","7","8","9","10","11","12")
  plot3 = barplot(y3,
                  #names.arg = names,
                  main = "Average abundances in octets",
                  xlab = "abundances")
  y4 = octets[[4]]
  #names = names = c("1", "2", "3", "4", "5", "6","7","8","9","10","11","12","13","14","15")
  barplot(y4,
          #names.arg = names,
          main = "Average abundances in octets",
          xlab = "abundances")


```

These are the octets from the coalescence simulation, which look very similar to the results of the simulation from the HPC (!).
Not totally sure why one is quiker - except that in the coalescence model you generate one community, then do the size of the community calculations, so for our sizes,that's a maximum of 10,000 cyles in the loop. For the neutral model you generate a new community of size N many times during the burn in, then you continue recreating new communities for the presest time in order to take an average over all the cyles. Therefore there are many more calculations. 


```{r, echo = FALSE}
############# Question 20 ##########################################
# Read in the files from the HPC
#couldnt work out easy wy of specifying files in each batch, so this first function
get_quartile = function(i) {
  if (i == 1) {
    quartile = c(1:24)
  }
  else if (i == 2) {
    quartile = c(27:49)
  }
  else if (i == 3) {
    quartile = c(52:74)
  }
  else {
    quartile = c(77:100)
  }
  return(quartile)
}

# This function returns the sum and number of the octets in single file, to be found in path specified
get_sum_and_length_of_octet = function(i) {
  #browser()
  infile = paste("../Results/Cluster_1207/pg5117/pg5117_cluster_", i, ".rda", sep = "")
  load(infile)
  len = length(octets)
  sum = vector()
  sum_and_length = list()
  for (a in 1:len) {
    sum = sum_vect(sum, octets[[a]])
  }
  sum_and_length[[1]] = sum
  sum_and_length[[2]] = len
  return(sum_and_length)
  
}


get_results = function() {
  #browser()
  ave_for_file_batch = list()
  for (i in 1:4) {
    j = get_quartile(i)    # this return vector of file numbers in each batch, eg if i = 2, 26:50
    cum_sum = vector()
    cum_len = 0
    results = list()
    for (counts in j) {
      results =  get_sum_and_length_of_octet(counts)
      cum_sum = sum_vect(cum_sum, results[[1]])
      cum_len =  results[[2]] + cum_len
    }
    ave_for_file_batch[[i]] = cum_sum / cum_len
    
  }
  return(ave_for_file_batch)
}

plot_results = function(results) {
  par(mfrow = c(2, 2))
  ave1 = results[[1]]
  #names = names = c("1", "2", "3", "4", "5", "6","7","8","9")
  plot1 = barplot(ave1,
                  #names.arg = names,
                  main = "Average abundances in octets",
                  xlab = "abundances")
  ave2 = results[[2]]
  #names = names = c("1", "2", "3", "4", "5", "6","7","8","9","10")
  plot2 = barplot(ave2,
                  #names.arg = names,
                  main = "Average abundances in octets",
                  xlab = "abundances")
  ave3 = results[[3]]
  #names = names = c("1", "2", "3", "4", "5", "6","7","8","9","10","11","12")
  plot3 = barplot(ave3,
                  #names.arg = names,
                  main = "Average abundances in octets",
                  xlab = "abundances")
  ave4 = results[[4]]
  #names = names = c("1", "2", "3", "4", "5", "6","7","8","9","10","11","12","13")
  barplot(ave4,
          #names.arg = names,
          main = "Average abundances in octets",
          xlab = "abundances")
}
results = get_results()
plot_results(results)
```


